{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import yfinance as yf\n",
    "import polygon \n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the timescaledb database\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get the postgres url\n",
    "postgres_url = os.environ.get('POSTGRES_URL')\n",
    "user = os.environ.get('POSTGRES_USER')\n",
    "password = os.environ.get('POSTGRES_PASSWORD')\n",
    "# Connect to the postgres database\n",
    "try:\n",
    "    conn = psycopg2.connect(postgres_url)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Connected to the timescaledb database\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to the database: {e}\")\n",
    "    conn = None\n",
    "    cursor = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect DuckDB to Timescale Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect Polar to Timescale Postgres\n",
    "duck_query = duckdb.sql(f\"\"\"\n",
    "    INSTALL postgres_scanner;\n",
    "    LOAD postgres_scanner;\n",
    "\n",
    "    SELECT * FROM postgres_scan(\n",
    "        'host=localhost port=5432 user={user} password={password} dbname=condvest',\n",
    "        'public', 'raw'\n",
    "    ) ORDER BY symbol, date DESC;\n",
    "\"\"\")\n",
    "\n",
    "duck_df = duck_query.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH raw_data AS (\n",
    "    SELECT * FROM postgres_scan(\n",
    "        'host=localhost port=5432 user={user} password={password} dbname=condvest',\n",
    "        'public', 'raw' \n",
    "    )\n",
    "),\n",
    "ranked AS (\n",
    "    SELECT *,\n",
    "        row_number() OVER (PARTITION BY symbol ORDER BY date) as rn\n",
    "    FROM raw_data\n",
    "),\n",
    "grouped AS (\n",
    "    SELECT *,\n",
    "        (rn - 1) / 3 as group_id\n",
    "    FROM ranked\n",
    ")\n",
    "SELECT \n",
    "    symbol,\n",
    "    min(date) as date,\n",
    "    first(open) as open,\n",
    "    max(high) as high,\n",
    "    min(low) as low,\n",
    "    last(close) as close,\n",
    "    sum(volume) as volume\n",
    "FROM grouped\n",
    "GROUP BY symbol, group_id\n",
    "ORDER BY symbol, date;\n",
    "\"\"\"\n",
    "\n",
    "%time duckdb_result = duckdb.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect Polar to Timescale Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Load from Timescale using ConnectorX\n",
    "polars_df = pl.read_database_uri(\n",
    "    \"SELECT date, symbol, open, high, low, close, volume FROM raw ORDER BY symbol ASC, date ASC\",\n",
    "    uri=postgres_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure datetime column is properly cast\n",
    "polars_df = polars_df.with_columns([\n",
    "    pl.col(\"date\").cast(pl.Datetime(\"us\"))\n",
    "])\n",
    "\n",
    "# Resample to 3-day OHLCV candles using Polars' groupby_dynamic\n",
    "resampled_3d_df = (\n",
    "    polars_df.group_by_dynamic(\n",
    "        index_column=\"date\",\n",
    "        every=\"3d\",\n",
    "        by=\"symbol\",\n",
    "        closed=\"left\",\n",
    "        period=\"3d\"\n",
    "    )\n",
    "    .agg([\n",
    "        pl.col(\"open\").first().alias(\"open\"),\n",
    "        pl.col(\"high\").max().alias(\"high\"),\n",
    "        pl.col(\"low\").min().alias(\"low\"),\n",
    "        pl.col(\"close\").last().alias(\"close\"),\n",
    "        pl.col(\"volume\").sum().alias(\"volume\")\n",
    "    ])\n",
    "    .sort([\"symbol\", \"date\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_3d_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DuckDB + Polar Add Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB query execution time: 0.06 seconds\n",
      "Duck to dataframe conversion time: 19.79 seconds\n",
      "DuckDB query execution time: 0.03 seconds\n",
      "Duck to dataframe conversion time: 12.24 seconds\n",
      "DuckDB query execution time: 0.03 seconds\n",
      "Duck to dataframe conversion time: 12.14 seconds\n",
      "DuckDB query execution time: 0.03 seconds\n",
      "Duck to dataframe conversion time: 13.52 seconds\n",
      "DuckDB query execution time: 0.03 seconds\n",
      "Duck to dataframe conversion time: 14.02 seconds\n",
      "Pandas to Polars conversion time: 15.60 seconds\n",
      "Indicator calculation time: 22.44 seconds\n",
      "\n",
      "First 10 rows of result:\n",
      "shape: (10, 17)\n",
      "┌────────┬─────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ symbol ┆ date        ┆ open      ┆ high      ┆ … ┆ EMA_55    ┆ EMA_89    ┆ macd_fast ┆ macd_slow │\n",
      "│ ---    ┆ ---         ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
      "│ str    ┆ datetime[μs ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
      "│        ┆ , America/E ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ dmonton]    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "╞════════╪═════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ A      ┆ 1999-11-18  ┆ 27.357426 ┆ 30.063108 ┆ … ┆ 26.455534 ┆ 26.455534 ┆ 0.0       ┆ 0.0       │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-18  ┆ 27.357426 ┆ 30.063108 ┆ … ┆ 26.455534 ┆ 26.455534 ┆ 0.0       ┆ 0.0       │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-18  ┆ 27.357426 ┆ 30.063108 ┆ … ┆ 26.455534 ┆ 26.455534 ┆ 0.0       ┆ 0.0       │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-18  ┆ 27.357426 ┆ 30.063108 ┆ … ┆ 26.455534 ┆ 26.455534 ┆ 0.0       ┆ 0.0       │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-18  ┆ 27.357426 ┆ 30.063108 ┆ … ┆ 26.455534 ┆ 26.455534 ┆ 0.0       ┆ 0.0       │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-19  ┆ 25.816683 ┆ 25.854263 ┆ … ┆ 26.058461 ┆ 26.07156  ┆ -0.061045 ┆ -0.013099 │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-19  ┆ 25.816683 ┆ 25.854263 ┆ … ┆ 25.775212 ┆ 25.797431 ┆ -0.099039 ┆ -0.022219 │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-19  ┆ 25.816683 ┆ 25.854263 ┆ … ┆ 25.563102 ┆ 25.591956 ┆ -0.122818 ┆ -0.028853 │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-19  ┆ 25.816683 ┆ 25.854263 ┆ … ┆ 25.398418 ┆ 25.432249 ┆ -0.137312 ┆ -0.033831 │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-19  ┆ 25.816683 ┆ 25.854263 ┆ … ┆ 25.266932 ┆ 25.30458  ┆ -0.145489 ┆ -0.037648 │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "└────────┴─────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import polars as pl\n",
    "import time\n",
    "\n",
    "# Step 1: Connect and load Postgres data into DuckDB\n",
    "con = duckdb.connect()\n",
    "\n",
    "combined_results = []\n",
    "intervals = [1,3,5,8,13]\n",
    "for interval in intervals:\n",
    "    start_time = time.time()\n",
    "\n",
    "    query = f\"\"\"\n",
    "    WITH raw_data AS (\n",
    "        SELECT * FROM postgres_scan(\n",
    "            'host=localhost port=5432 user={user} password={password} dbname=condvest',\n",
    "            'public', 'raw'\n",
    "        )\n",
    "    ),\n",
    "    ranked AS (\n",
    "        SELECT *,\n",
    "            row_number() OVER (PARTITION BY symbol ORDER BY date) as rn\n",
    "        FROM raw_data\n",
    "    ),\n",
    "    grouped AS (\n",
    "        SELECT *,\n",
    "            (rn - 1) / {interval} as group_id\n",
    "        FROM ranked\n",
    "    )\n",
    "    SELECT \n",
    "        symbol,\n",
    "        min(date) as date,\n",
    "        first(open) as open,\n",
    "        max(high) as high,\n",
    "        min(low) as low,\n",
    "        last(close) as close,\n",
    "        sum(volume) as volume,\n",
    "        '{interval}'::INT as interval\n",
    "    FROM grouped\n",
    "    GROUP BY symbol, group_id\n",
    "    ORDER BY symbol, date;\n",
    "    \"\"\"\n",
    "    \n",
    "    df = duckdb.sql(query)\n",
    "    print(f\"DuckDB query execution time: {time.time() - start_time:.2f} seconds\")\n",
    "    combined_results.append(df.df())\n",
    "    print(f\"Duck to dataframe conversion time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Step 2: Convert to Polars DataFrame\n",
    "start_time = time.time()\n",
    "pl_resampled_df = pl.from_pandas(pd.concat(combined_results))\n",
    "print(f\"Pandas to Polars conversion time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Step 3: Convert to Polars and add indicators\n",
    "def add_indicators(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    df = df.sort(\"date\")\n",
    "    \n",
    "    # Step 1: Compute EMAs\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"close\").ewm_mean(span=8).alias(\"EMA_8\"),\n",
    "        pl.col(\"close\").ewm_mean(span=13).alias(\"EMA_13\"),\n",
    "        pl.col(\"close\").ewm_mean(span=21).alias(\"EMA_21\"),\n",
    "        pl.col(\"close\").ewm_mean(span=144).alias(\"EMA_144\"),\n",
    "        pl.col(\"close\").ewm_mean(span=169).alias(\"EMA_169\"),\n",
    "        pl.col(\"close\").ewm_mean(span=55).alias(\"EMA_55\"),\n",
    "        pl.col(\"close\").ewm_mean(span=89).alias(\"EMA_89\"),\n",
    "    ])\n",
    "    \n",
    "    # Step 2: Compute MACD and RSI using already-created columns\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"EMA_13\") - pl.col(\"EMA_21\")).alias(\"macd_fast\"),\n",
    "        (pl.col(\"EMA_55\") - pl.col(\"EMA_89\")).alias(\"macd_slow\"),\n",
    "    ])\n",
    "    \n",
    "    return df\n",
    "\n",
    "start_time = time.time()\n",
    "df_with_indicators = pl_resampled_df.group_by(\"symbol\", maintain_order=True).map_groups(add_indicators)\n",
    "print(f\"Indicator calculation time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\nFirst 10 rows of result:\")\n",
    "print(df_with_indicators.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "class TrendAlertProcessor:\n",
    "    \"\"\"\n",
    "    TrendAlertProcessor using Polars for efficient processing of financial time series data.\n",
    "    Incorporates advanced trend detection algorithms from the dictionary-based implementation.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pl.DataFrame, intervals: List[int]):\n",
    "        self.df = df\n",
    "        self.intervals = intervals\n",
    "        self.rolling_window = 50\n",
    "    \n",
    "    def _add_velocity_alert(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Add velocity alerts based on the relationship between price and various EMAs.\n",
    "        Similar to velocity_alert_dict in the original implementation.\n",
    "        \"\"\"\n",
    "        # Add velocity status\n",
    "        df = df.with_columns([\n",
    "            pl.when(\n",
    "                (pl.col(\"close\") > pl.col(\"open\")) & \n",
    "                (pl.col(\"close\") > pl.max_horizontal(\"EMA_8\", \"EMA_13\")) & \n",
    "                (pl.col(\"close\") > pl.max_horizontal(\"EMA_144\", \"EMA_169\")) &\n",
    "                (pl.min_horizontal(\"EMA_8\", \"EMA_13\") > pl.max_horizontal(\"EMA_144\", \"EMA_169\"))\n",
    "            ).then(pl.lit(\"velocity_maintained\"))\n",
    "            .when(\n",
    "                (pl.col(\"close\") < pl.col(\"EMA_13\")) & \n",
    "                (pl.col(\"close\") > pl.col(\"EMA_169\"))\n",
    "            ).then(pl.lit(\"velocity_weak\"))\n",
    "            .when(\n",
    "                (pl.col(\"close\") < pl.col(\"EMA_13\")) & \n",
    "                (pl.col(\"close\") < pl.col(\"EMA_169\"))\n",
    "            ).then(pl.lit(\"velocity_loss\"))\n",
    "            .otherwise(pl.lit(\"velocity_negotiating\"))\n",
    "            .alias(\"velocity_status\")\n",
    "        ])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _add_accel_decel_alert(self, df: pl.DataFrame, interval: int) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Add acceleration/deceleration alerts based on EMA relationships and velocity status history.\n",
    "        \"\"\"\n",
    "        window_dict = {\n",
    "            1: 28, 3: 20, 5: 20, 8: 14, 13: 14\n",
    "        }\n",
    "        obs_window = window_dict.get(interval, 7)\n",
    "        \n",
    "        # First get velocity status\n",
    "        df = self._add_velocity_alert(df)\n",
    "        \n",
    "        # Count velocity statuses in the observation window\n",
    "        df = df.with_columns([\n",
    "            pl.col(\"velocity_status\").map_elements(\n",
    "                lambda s: 1 if s in [\"velocity_loss\", \"velocity_weak\", \"velocity_negotiating\"] else 0,\n",
    "                return_dtype=pl.Int32\n",
    "            ).alias(\"loss_flag\"),\n",
    "            pl.col(\"velocity_status\").map_elements(\n",
    "                lambda s: 1 if s == \"velocity_maintained\" else 0,\n",
    "                return_dtype=pl.Int32\n",
    "            ).alias(\"maintain_flag\")\n",
    "        ])\n",
    "        \n",
    "        df = df.with_columns([\n",
    "            pl.col(\"loss_flag\").rolling_sum(window_size=obs_window).alias(\"count_velocity_loss\"),\n",
    "            pl.col(\"maintain_flag\").rolling_sum(window_size=obs_window).alias(\"count_velocity_maintained\")\n",
    "        ])\n",
    "        \n",
    "        # Add acceleration/deceleration signals\n",
    "        df = df.with_columns([\n",
    "            pl.when(\n",
    "                (pl.max_horizontal(\"EMA_144\", \"EMA_169\") <= pl.max_horizontal(\"EMA_8\", \"EMA_13\")) &\n",
    "                (pl.col(\"open\") < pl.col(\"close\")) &\n",
    "                (pl.col(\"count_velocity_loss\") > pl.col(\"count_velocity_maintained\"))\n",
    "            ).then(pl.lit(\"accelerated\"))\n",
    "            .when(\n",
    "                (pl.col(\"close\") < pl.min_horizontal(\"EMA_8\", \"EMA_13\")) &\n",
    "                (pl.col(\"count_velocity_maintained\") < pl.col(\"count_velocity_loss\"))\n",
    "            ).then(pl.lit(\"decelerated\"))\n",
    "            .otherwise(None).alias(\"momentum_signal\")\n",
    "        ])\n",
    "        \n",
    "        # Create alert\n",
    "        momentum_alerts = df.filter(pl.col(\"momentum_signal\").is_not_null())\n",
    "        momentum_alerts = momentum_alerts.with_columns([\n",
    "            pl.lit(\"momentum_alert\").alias(\"alert_type\"),\n",
    "            pl.col(\"momentum_signal\").alias(\"signal\"),\n",
    "            pl.lit(interval).alias(\"interval\")\n",
    "        ])\n",
    "        \n",
    "        return momentum_alerts.select(\"symbol\", \"date\", \"interval\", \"alert_type\", \"signal\")\n",
    "    \n",
    "    def _add_ema_touch_alert(self, df: pl.DataFrame, interval: int) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Add alerts for when price touches or comes close to important EMAs.\n",
    "        \"\"\"\n",
    "        tolerance_dict = {\n",
    "            1: 0.002, 3: 0.02, 5: 0.05, 8: 0.07, 13: 0.1\n",
    "        }\n",
    "        tolerance = tolerance_dict.get(interval, 0.02)\n",
    "        \n",
    "        # Calculate tolerance bands around EMAs\n",
    "        df = df.with_columns([\n",
    "            pl.min_horizontal(\n",
    "                pl.col(\"EMA_144\"), pl.col(\"EMA_169\")\n",
    "            ).fill_null(pl.col(\"EMA_13\")).alias(\"long_term_min\"),\n",
    "            \n",
    "            pl.max_horizontal(\n",
    "                pl.col(\"EMA_144\"), pl.col(\"EMA_169\")\n",
    "            ).fill_null(pl.col(\"EMA_13\")).alias(\"long_term_max\"),\n",
    "            \n",
    "            pl.min_horizontal(\n",
    "                pl.col(\"EMA_8\"), pl.col(\"EMA_13\")\n",
    "            ).alias(\"short_term_min\"),\n",
    "            \n",
    "            pl.max_horizontal(\n",
    "                pl.col(\"EMA_8\"), pl.col(\"EMA_13\")\n",
    "            ).alias(\"short_term_max\")\n",
    "        ])\n",
    "        \n",
    "        # Calculate tolerance bands\n",
    "        df = df.with_columns([\n",
    "            (pl.col(\"long_term_min\") * (1 - tolerance)).alias(\"lower_bound\"),\n",
    "            (pl.col(\"long_term_max\") * (1 + tolerance)).alias(\"upper_bound\")\n",
    "        ])\n",
    "        \n",
    "        # Detect touches\n",
    "        df = df.with_columns([\n",
    "            pl.when(\n",
    "                ((pl.col(\"low\") <= pl.col(\"upper_bound\")) & (pl.col(\"low\") >= pl.col(\"lower_bound\"))) |\n",
    "                ((pl.col(\"EMA_13\") <= pl.col(\"upper_bound\")) & (pl.col(\"EMA_13\") >= pl.col(\"lower_bound\"))) |\n",
    "                ((pl.col(\"EMA_8\") <= pl.col(\"upper_bound\")) & (pl.col(\"EMA_8\") >= pl.col(\"lower_bound\")))\n",
    "            ).then(\n",
    "                pl.when(\n",
    "                    (pl.col(\"short_term_min\") > pl.col(\"long_term_max\")) &\n",
    "                    (pl.min_horizontal(pl.col(\"close\"), pl.col(\"open\")) > pl.col(\"long_term_min\"))\n",
    "                ).then(pl.lit(\"support\"))\n",
    "                .when(\n",
    "                    (pl.col(\"short_term_max\") < pl.col(\"long_term_max\")) &\n",
    "                    (pl.col(\"close\") < pl.col(\"long_term_max\"))\n",
    "                ).then(pl.lit(\"resistance\"))\n",
    "                .otherwise(pl.lit(\"neutral\"))\n",
    "            ).otherwise(None).alias(\"ema_touch_type\")\n",
    "        ])\n",
    "        \n",
    "        # Filter for touches and create alert\n",
    "        ema_touch_alerts = df.filter(pl.col(\"ema_touch_type\").is_not_null())\n",
    "        ema_touch_alerts = ema_touch_alerts.with_columns([\n",
    "            pl.lit(\"ema_touch\").alias(\"alert_type\"),\n",
    "            pl.col(\"ema_touch_type\").alias(\"signal\"),\n",
    "            pl.lit(interval).alias(\"interval\")\n",
    "        ])\n",
    "        \n",
    "        return ema_touch_alerts.select(\"symbol\", \"date\", \"interval\", \"alert_type\", \"signal\")\n",
    "    \n",
    "    def apply(self) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Apply all alert detection algorithms and return a combined DataFrame of alerts.\n",
    "        \"\"\"\n",
    "        all_alerts = []\n",
    "        \n",
    "        for interval in self.intervals:\n",
    "            df_interval = self.df.filter(pl.col(\"interval\") == interval)\n",
    "            \n",
    "            # No empty DataFrames\n",
    "            if df_interval.height == 0:\n",
    "                continue\n",
    "                \n",
    "            # Add velocity alerts\n",
    "            velocity_df = self._add_velocity_alert(df_interval)\n",
    "            velocity_alerts = velocity_df.with_columns([\n",
    "                pl.lit(\"velocity_alert\").alias(\"alert_type\"),\n",
    "                pl.col(\"velocity_status\").alias(\"signal\"),\n",
    "                pl.lit(interval).alias(\"interval\")\n",
    "            ]).select(\"symbol\", \"date\", \"interval\", \"alert_type\", \"signal\")\n",
    "            \n",
    "            # Add momentum alerts\n",
    "            momentum_alerts = self._add_accel_decel_alert(df_interval, interval)\n",
    "            \n",
    "            # Add EMA touch alerts\n",
    "            ema_touch_alerts = self._add_ema_touch_alert(df_interval, interval)\n",
    "            \n",
    "            # Combine all alerts for this interval\n",
    "            all_alerts.extend([\n",
    "                velocity_alerts,\n",
    "                momentum_alerts,\n",
    "                ema_touch_alerts\n",
    "            ])\n",
    "        \n",
    "        # Combine all alerts into a single DataFrame\n",
    "        if all_alerts:\n",
    "            return pl.concat(all_alerts)\n",
    "        else:\n",
    "            # Return empty DataFrame with correct schema if no alerts\n",
    "            return pl.DataFrame({\n",
    "                \"symbol\": [],\n",
    "                \"date\": [],\n",
    "                \"interval\": [],\n",
    "                \"alert_type\": [],\n",
    "                \"signal\": []\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌────────┬────────────────────────────────┬──────────┬────────────────┬──────────────────────┐\n",
      "│ symbol ┆ date                           ┆ interval ┆ alert_type     ┆ signal               │\n",
      "│ ---    ┆ ---                            ┆ ---      ┆ ---            ┆ ---                  │\n",
      "│ str    ┆ datetime[μs, America/Edmonton] ┆ i32      ┆ str            ┆ str                  │\n",
      "╞════════╪════════════════════════════════╪══════════╪════════════════╪══════════════════════╡\n",
      "│ A      ┆ 1999-11-18 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_negotiating │\n",
      "│ A      ┆ 1999-11-19 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_loss        │\n",
      "│ A      ┆ 1999-11-22 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_negotiating │\n",
      "│ A      ┆ 1999-11-23 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_loss        │\n",
      "│ A      ┆ 1999-11-24 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_loss        │\n",
      "└────────┴────────────────────────────────┴──────────┴────────────────┴──────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "trend_alert = TrendAlertProcessor(df_with_indicators, intervals=[1, 3, 5, 8, 13])\n",
    "alert_df = trend_alert.apply()\n",
    "print(alert_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
