{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import yfinance as yf\n",
    "import polygon \n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the timescaledb database\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get the postgres url\n",
    "postgres_url = os.environ.get('POSTGRES_URL')\n",
    "user = os.environ.get('POSTGRES_USER')\n",
    "password = os.environ.get('POSTGRES_PASSWORD')\n",
    "intervals = [1, 3, 5, 8, 13]\n",
    "# Connect to the postgres database\n",
    "try:\n",
    "    conn = psycopg2.connect(postgres_url)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Connected to the timescaledb database\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to the database: {e}\")\n",
    "    conn = None\n",
    "    cursor = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 4.77 s, total: 19.6 s\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "# Connect to TimescaleDB\n",
    "conn = psycopg2.connect(postgres_url)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Query TimescaleDB\n",
    "query = \"SELECT * FROM raw ORDER BY symbol, date DESC\"\n",
    "cursor.execute(query)\n",
    "\n",
    "# Fetch results\n",
    "%time results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 s, sys: 9.59 s, total: 20.7 s\n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "## Connect Polar to Timescale Postgres\n",
    "duck_query = duckdb.sql(f\"\"\"\n",
    "    -- INSTALL postgres_scanner;\n",
    "    -- LOAD postgres_scanner;\n",
    "\n",
    "    SELECT * FROM postgres_scan(\n",
    "        'host=localhost port=5432 user={user} password={password} dbname=condvest',\n",
    "        'public', 'raw'\n",
    "    ) ORDER BY symbol, date DESC;\n",
    "\"\"\")\n",
    "\n",
    "%time duck_df = duck_query.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.13 ms, sys: 1.25 ms, total: 2.38 ms\n",
      "Wall time: 30 ms\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "WITH raw_data AS (\n",
    "    SELECT * FROM postgres_scan(\n",
    "        'host=localhost port=5432 user={user} password={password} dbname=condvest',\n",
    "        'public', 'raw' \n",
    "    )\n",
    "),\n",
    "ranked AS (\n",
    "    SELECT *,\n",
    "        row_number() OVER (PARTITION BY symbol ORDER BY date) as rn\n",
    "    FROM raw_data\n",
    "),\n",
    "grouped AS (\n",
    "    SELECT *,\n",
    "        (rn - 1) / 3 as group_id\n",
    "    FROM ranked\n",
    ")\n",
    "SELECT \n",
    "    symbol,\n",
    "    min(date) as date,\n",
    "    first(open) as open,\n",
    "    max(high) as high,\n",
    "    min(low) as low,\n",
    "    last(close) as close,\n",
    "    sum(volume) as volume\n",
    "FROM grouped\n",
    "GROUP BY symbol, group_id\n",
    "ORDER BY symbol, date;\n",
    "\"\"\"\n",
    "\n",
    "%time duckdb_result = duckdb.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Load from Timescale using ConnectorX\n",
    "polars_df = pl.read_database_uri(\n",
    "    \"SELECT date, symbol, open, high, low, close, volume FROM raw ORDER BY symbol ASC, date ASC\",\n",
    "    uri=postgres_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure datetime column is properly cast\n",
    "polars_df = polars_df.with_columns([\n",
    "    pl.col(\"date\").cast(pl.Datetime(\"us\"))\n",
    "])\n",
    "\n",
    "# Resample to 3-day OHLCV candles using Polars' groupby_dynamic\n",
    "resampled_3d_df = (\n",
    "    polars_df.group_by_dynamic(\n",
    "        index_column=\"date\",\n",
    "        every=\"3d\",\n",
    "        by=\"symbol\",\n",
    "        closed=\"left\",\n",
    "        period=\"3d\"\n",
    "    )\n",
    "    .agg([\n",
    "        pl.col(\"open\").first().alias(\"open\"),\n",
    "        pl.col(\"high\").max().alias(\"high\"),\n",
    "        pl.col(\"low\").min().alias(\"low\"),\n",
    "        pl.col(\"close\").last().alias(\"close\"),\n",
    "        pl.col(\"volume\").sum().alias(\"volume\")\n",
    "    ])\n",
    "    .sort([\"symbol\", \"date\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_3d_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. DuckDB + Polar Add Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB query execution time: 0.07 seconds\n",
      "Duck to dataframe conversion time: 13.94 seconds\n",
      "DuckDB query execution time: 0.03 seconds\n",
      "Duck to dataframe conversion time: 14.20 seconds\n",
      "DuckDB query execution time: 0.03 seconds\n",
      "Duck to dataframe conversion time: 14.69 seconds\n",
      "DuckDB query execution time: 0.04 seconds\n",
      "Duck to dataframe conversion time: 14.69 seconds\n",
      "DuckDB query execution time: 0.04 seconds\n",
      "Duck to dataframe conversion time: 16.49 seconds\n",
      "Pandas to Polars conversion time: 20.28 seconds\n",
      "Indicator calculation time: 21.02 seconds\n",
      "\n",
      "First 10 rows of result:\n",
      "shape: (10, 17)\n",
      "┌────────┬─────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ symbol ┆ date        ┆ open      ┆ high      ┆ … ┆ EMA_55    ┆ EMA_89    ┆ macd_fast ┆ macd_slow │\n",
      "│ ---    ┆ ---         ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
      "│ str    ┆ datetime[μs ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
      "│        ┆ , America/E ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ dmonton]    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "╞════════╪═════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ A      ┆ 1999-11-18  ┆ 27.357426 ┆ 30.063108 ┆ … ┆ 26.455534 ┆ 26.455534 ┆ 0.0       ┆ 0.0       │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-18  ┆ 27.357426 ┆ 30.063108 ┆ … ┆ 26.455534 ┆ 26.455534 ┆ 0.0       ┆ 0.0       │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-18  ┆ 27.357426 ┆ 30.063108 ┆ … ┆ 26.455534 ┆ 26.455534 ┆ 0.0       ┆ 0.0       │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-18  ┆ 27.357426 ┆ 30.063108 ┆ … ┆ 26.455534 ┆ 26.455534 ┆ 0.0       ┆ 0.0       │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-18  ┆ 27.357426 ┆ 30.063108 ┆ … ┆ 26.455534 ┆ 26.455534 ┆ 0.0       ┆ 0.0       │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-19  ┆ 25.816683 ┆ 25.854263 ┆ … ┆ 26.058461 ┆ 26.07156  ┆ -0.061045 ┆ -0.013099 │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-19  ┆ 25.816683 ┆ 25.854263 ┆ … ┆ 25.775212 ┆ 25.797431 ┆ -0.099039 ┆ -0.022219 │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-19  ┆ 25.816683 ┆ 25.854263 ┆ … ┆ 25.563102 ┆ 25.591956 ┆ -0.122818 ┆ -0.028853 │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-19  ┆ 25.816683 ┆ 25.854263 ┆ … ┆ 25.398418 ┆ 25.432249 ┆ -0.137312 ┆ -0.033831 │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-19  ┆ 25.816683 ┆ 25.854263 ┆ … ┆ 25.266932 ┆ 25.30458  ┆ -0.145489 ┆ -0.037648 │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "└────────┴─────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import polars as pl\n",
    "import time\n",
    "\n",
    "# Step 1: Connect and load Postgres data into DuckDB\n",
    "con = duckdb.connect()\n",
    "\n",
    "combined_results = []\n",
    "intervals = [1,3,5,8,13]\n",
    "for interval in intervals:\n",
    "    start_time = time.time()\n",
    "\n",
    "    query = f\"\"\"\n",
    "    WITH raw_data AS (\n",
    "        SELECT * FROM postgres_scan(\n",
    "            'host=localhost port=5432 user={user} password={password} dbname=condvest',\n",
    "            'public', 'raw'\n",
    "        )\n",
    "    ),\n",
    "    ranked AS (\n",
    "        SELECT *,\n",
    "            row_number() OVER (PARTITION BY symbol ORDER BY date) as rn\n",
    "        FROM raw_data\n",
    "    ),\n",
    "    grouped AS (\n",
    "        SELECT *,\n",
    "            (rn - 1) / {interval} as group_id\n",
    "        FROM ranked\n",
    "    )\n",
    "    SELECT \n",
    "        symbol,\n",
    "        min(date) as date,\n",
    "        first(open) as open,\n",
    "        max(high) as high,\n",
    "        min(low) as low,\n",
    "        last(close) as close,\n",
    "        sum(volume) as volume,\n",
    "        '{interval}'::INT as interval\n",
    "    FROM grouped\n",
    "    GROUP BY symbol, group_id\n",
    "    ORDER BY symbol, date;\n",
    "    \"\"\"\n",
    "    \n",
    "    df = duckdb.sql(query)\n",
    "    print(f\"DuckDB query execution time: {time.time() - start_time:.2f} seconds\")\n",
    "    combined_results.append(df.df())\n",
    "    print(f\"Duck to dataframe conversion time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Step 2: Convert to Polars DataFrame\n",
    "start_time = time.time()\n",
    "pl_resampled_df = pl.from_pandas(pd.concat(combined_results))\n",
    "print(f\"Pandas to Polars conversion time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Step 3: Convert to Polars and add indicators\n",
    "def add_indicators(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    df = df.sort(\"date\")\n",
    "    \n",
    "    # Step 1: Compute EMAs\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"close\").ewm_mean(span=8).alias(\"EMA_8\"),\n",
    "        pl.col(\"close\").ewm_mean(span=13).alias(\"EMA_13\"),\n",
    "        pl.col(\"close\").ewm_mean(span=21).alias(\"EMA_21\"),\n",
    "        pl.col(\"close\").ewm_mean(span=144).alias(\"EMA_144\"),\n",
    "        pl.col(\"close\").ewm_mean(span=169).alias(\"EMA_169\"),\n",
    "        pl.col(\"close\").ewm_mean(span=55).alias(\"EMA_55\"),\n",
    "        pl.col(\"close\").ewm_mean(span=89).alias(\"EMA_89\"),\n",
    "    ])\n",
    "    \n",
    "    # Step 2: Compute MACD and RSI using already-created columns\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"EMA_13\") - pl.col(\"EMA_21\")).alias(\"macd_fast\"),\n",
    "        (pl.col(\"EMA_55\") - pl.col(\"EMA_89\")).alias(\"macd_slow\"),\n",
    "    ])\n",
    "    \n",
    "    return df\n",
    "\n",
    "start_time = time.time()\n",
    "df_with_indicators = pl_resampled_df.group_by(\"symbol\", maintain_order=True).map_groups(add_indicators)\n",
    "print(f\"Indicator calculation time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\nFirst 10 rows of result:\")\n",
    "print(df_with_indicators.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of alerts:\n",
      "shape: (10, 5)\n",
      "┌────────┬────────────────────────────────┬──────────┬────────────────┬──────────────────────┐\n",
      "│ symbol ┆ date                           ┆ interval ┆ alert_type     ┆ signal               │\n",
      "│ ---    ┆ ---                            ┆ ---      ┆ ---            ┆ ---                  │\n",
      "│ str    ┆ datetime[μs, America/Edmonton] ┆ i32      ┆ str            ┆ str                  │\n",
      "╞════════╪════════════════════════════════╪══════════╪════════════════╪══════════════════════╡\n",
      "│ A      ┆ 2020-01-02 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_maintained  │\n",
      "│ A      ┆ 2020-01-03 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_weak        │\n",
      "│ A      ┆ 2020-01-06 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_weak        │\n",
      "│ A      ┆ 2020-01-07 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_maintained  │\n",
      "│ A      ┆ 2020-01-08 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_negotiating │\n",
      "│ A      ┆ 2020-01-09 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_maintained  │\n",
      "│ A      ┆ 2020-01-10 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_negotiating │\n",
      "│ A      ┆ 2020-01-13 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_negotiating │\n",
      "│ A      ┆ 2020-01-14 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_maintained  │\n",
      "│ A      ┆ 2020-01-15 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_maintained  │\n",
      "└────────┴────────────────────────────────┴──────────┴────────────────┴──────────────────────┘\n",
      "\n",
      "First 5 momentum alerts:\n",
      "shape: (5, 5)\n",
      "┌────────┬────────────────────────────────┬──────────┬────────────────┬─────────────┐\n",
      "│ symbol ┆ date                           ┆ interval ┆ alert_type     ┆ signal      │\n",
      "│ ---    ┆ ---                            ┆ ---      ┆ ---            ┆ ---         │\n",
      "│ str    ┆ datetime[μs, America/Edmonton] ┆ i32      ┆ str            ┆ str         │\n",
      "╞════════╪════════════════════════════════╪══════════╪════════════════╪═════════════╡\n",
      "│ A      ┆ 2020-02-13 00:00:00 MST        ┆ 1        ┆ momentum_alert ┆ accelerated │\n",
      "│ A      ┆ 2020-02-14 00:00:00 MST        ┆ 1        ┆ momentum_alert ┆ accelerated │\n",
      "│ A      ┆ 2020-02-18 00:00:00 MST        ┆ 1        ┆ momentum_alert ┆ decelerated │\n",
      "│ A      ┆ 2020-02-20 00:00:00 MST        ┆ 1        ┆ momentum_alert ┆ decelerated │\n",
      "│ A      ┆ 2020-02-24 00:00:00 MST        ┆ 1        ┆ momentum_alert ┆ decelerated │\n",
      "└────────┴────────────────────────────────┴──────────┴────────────────┴─────────────┘\n",
      "\n",
      "First 5 EMA touch alerts:\n",
      "shape: (5, 5)\n",
      "┌────────┬────────────────────────────────┬──────────┬────────────┬─────────┐\n",
      "│ symbol ┆ date                           ┆ interval ┆ alert_type ┆ signal  │\n",
      "│ ---    ┆ ---                            ┆ ---      ┆ ---        ┆ ---     │\n",
      "│ str    ┆ datetime[μs, America/Edmonton] ┆ i32      ┆ str        ┆ str     │\n",
      "╞════════╪════════════════════════════════╪══════════╪════════════╪═════════╡\n",
      "│ A      ┆ 2020-01-27 00:00:00 MST        ┆ 1        ┆ ema_touch  ┆ support │\n",
      "│ A      ┆ 2020-01-28 00:00:00 MST        ┆ 1        ┆ ema_touch  ┆ support │\n",
      "│ A      ┆ 2020-02-12 00:00:00 MST        ┆ 1        ┆ ema_touch  ┆ neutral │\n",
      "│ A      ┆ 2020-02-13 00:00:00 MST        ┆ 1        ┆ ema_touch  ┆ neutral │\n",
      "│ A      ┆ 2020-02-14 00:00:00 MST        ┆ 1        ┆ ema_touch  ┆ support │\n",
      "└────────┴────────────────────────────────┴──────────┴────────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "# Define intervals and rolling window\n",
    "intervals = [1, 3, 5, 8, 13]\n",
    "rolling_window = 50\n",
    "\n",
    "# Step 1: Add velocity alerts\n",
    "def add_velocity_alert(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Add velocity alerts based on the relationship between price and various EMAs.\n",
    "    \"\"\"\n",
    "    df = df.with_columns([\n",
    "        pl.when(\n",
    "            (pl.col(\"close\") > pl.col(\"open\")) & \n",
    "            (pl.col(\"close\") > pl.max_horizontal(\"EMA_8\", \"EMA_13\")) & \n",
    "            (pl.col(\"close\") > pl.max_horizontal(\"EMA_144\", \"EMA_169\")) &\n",
    "            (pl.min_horizontal(\"EMA_8\", \"EMA_13\") > pl.max_horizontal(\"EMA_144\", \"EMA_169\"))\n",
    "        ).then(pl.lit(\"velocity_maintained\"))\n",
    "        .when(\n",
    "            (pl.col(\"close\") < pl.col(\"EMA_13\")) & \n",
    "            (pl.col(\"close\") > pl.col(\"EMA_169\"))\n",
    "        ).then(pl.lit(\"velocity_weak\"))\n",
    "        .when(\n",
    "            (pl.col(\"close\") < pl.col(\"EMA_13\")) & \n",
    "            (pl.col(\"close\") < pl.col(\"EMA_169\"))\n",
    "        ).then(pl.lit(\"velocity_loss\"))\n",
    "        .otherwise(pl.lit(\"velocity_negotiating\"))\n",
    "        .alias(\"velocity_status\")\n",
    "    ])\n",
    "    return df\n",
    "\n",
    "# Step 2: Add acceleration/deceleration alerts\n",
    "def add_accel_decel_alert(df: pl.DataFrame, interval: int) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Add acceleration/deceleration alerts based on EMA relationships and velocity status history.\n",
    "    \"\"\"\n",
    "    window_dict = {\n",
    "        1: 28, 3: 20, 5: 20, 8: 14, 13: 14\n",
    "    }\n",
    "    obs_window = window_dict.get(interval, 7)\n",
    "    \n",
    "    # First get velocity status\n",
    "    df = add_velocity_alert(df)\n",
    "    \n",
    "    # Count velocity statuses in the observation window\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"velocity_status\").map_elements(\n",
    "            lambda s: 1 if s in [\"velocity_loss\", \"velocity_weak\", \"velocity_negotiating\"] else 0,\n",
    "            return_dtype=pl.Int32\n",
    "        ).alias(\"loss_flag\"),\n",
    "        pl.col(\"velocity_status\").map_elements(\n",
    "            lambda s: 1 if s == \"velocity_maintained\" else 0,\n",
    "            return_dtype=pl.Int32\n",
    "        ).alias(\"maintain_flag\")\n",
    "    ])\n",
    "    \n",
    "    df = df.with_columns([\n",
    "        pl.col(\"loss_flag\").rolling_sum(window_size=obs_window).alias(\"count_velocity_loss\"),\n",
    "        pl.col(\"maintain_flag\").rolling_sum(window_size=obs_window).alias(\"count_velocity_maintained\")\n",
    "    ])\n",
    "    \n",
    "    # Add acceleration/deceleration signals\n",
    "    df = df.with_columns([\n",
    "        pl.when(\n",
    "            (pl.max_horizontal(\"EMA_144\", \"EMA_169\") <= pl.max_horizontal(\"EMA_8\", \"EMA_13\")) &\n",
    "            (pl.col(\"open\") < pl.col(\"close\")) &\n",
    "            (pl.col(\"count_velocity_loss\") > pl.col(\"count_velocity_maintained\"))\n",
    "        ).then(pl.lit(\"accelerated\"))\n",
    "        .when(\n",
    "            (pl.col(\"close\") < pl.min_horizontal(\"EMA_8\", \"EMA_13\")) &\n",
    "            (pl.col(\"count_velocity_maintained\") < pl.col(\"count_velocity_loss\"))\n",
    "        ).then(pl.lit(\"decelerated\"))\n",
    "        .otherwise(None).alias(\"momentum_signal\")\n",
    "    ])\n",
    "    \n",
    "    # Create alert\n",
    "    momentum_alerts = df.filter(pl.col(\"momentum_signal\").is_not_null())\n",
    "    momentum_alerts = momentum_alerts.with_columns([\n",
    "        pl.lit(\"momentum_alert\").alias(\"alert_type\"),\n",
    "        pl.col(\"momentum_signal\").alias(\"signal\"),\n",
    "        pl.lit(interval).alias(\"interval\")\n",
    "    ])\n",
    "    \n",
    "    return momentum_alerts.select(\"symbol\", \"date\", \"interval\", \"alert_type\", \"signal\")\n",
    "\n",
    "# Step 3: Add EMA touch alerts\n",
    "def add_ema_touch_alert(df: pl.DataFrame, interval: int) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Add alerts for when price touches or comes close to important EMAs.\n",
    "    \"\"\"\n",
    "    tolerance_dict = {\n",
    "        1: 0.002, 3: 0.02, 5: 0.05, 8: 0.07, 13: 0.1\n",
    "    }\n",
    "    tolerance = tolerance_dict.get(interval, 0.02)\n",
    "    \n",
    "    # Calculate tolerance bands around EMAs\n",
    "    df = df.with_columns([\n",
    "        pl.min_horizontal(\n",
    "            pl.col(\"EMA_144\"), pl.col(\"EMA_169\")\n",
    "        ).fill_null(pl.col(\"EMA_13\")).alias(\"long_term_min\"),\n",
    "        \n",
    "        pl.max_horizontal(\n",
    "            pl.col(\"EMA_144\"), pl.col(\"EMA_169\")\n",
    "        ).fill_null(pl.col(\"EMA_13\")).alias(\"long_term_max\"),\n",
    "        \n",
    "        pl.min_horizontal(\n",
    "            pl.col(\"EMA_8\"), pl.col(\"EMA_13\")\n",
    "        ).alias(\"short_term_min\"),\n",
    "        \n",
    "        pl.max_horizontal(\n",
    "            pl.col(\"EMA_8\"), pl.col(\"EMA_13\")\n",
    "        ).alias(\"short_term_max\")\n",
    "    ])\n",
    "    \n",
    "    # Calculate tolerance bands\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"long_term_min\") * (1 - tolerance)).alias(\"lower_bound\"),\n",
    "        (pl.col(\"long_term_max\") * (1 + tolerance)).alias(\"upper_bound\")\n",
    "    ])\n",
    "    \n",
    "    # Detect touches\n",
    "    df = df.with_columns([\n",
    "        pl.when(\n",
    "            ((pl.col(\"low\") <= pl.col(\"upper_bound\")) & (pl.col(\"low\") >= pl.col(\"lower_bound\"))) |\n",
    "            ((pl.col(\"EMA_13\") <= pl.col(\"upper_bound\")) & (pl.col(\"EMA_13\") >= pl.col(\"lower_bound\"))) |\n",
    "            ((pl.col(\"EMA_8\") <= pl.col(\"upper_bound\")) & (pl.col(\"EMA_8\") >= pl.col(\"lower_bound\")))\n",
    "        ).then(\n",
    "            pl.when(\n",
    "                (pl.col(\"short_term_min\") > pl.col(\"long_term_max\")) &\n",
    "                (pl.min_horizontal(pl.col(\"close\"), pl.col(\"open\")) > pl.col(\"long_term_min\"))\n",
    "            ).then(pl.lit(\"support\"))\n",
    "            .when(\n",
    "                (pl.col(\"short_term_max\") < pl.col(\"long_term_max\")) &\n",
    "                (pl.col(\"close\") < pl.col(\"long_term_max\"))\n",
    "            ).then(pl.lit(\"resistance\"))\n",
    "            .otherwise(pl.lit(\"neutral\"))\n",
    "        ).otherwise(None).alias(\"ema_touch_type\")\n",
    "    ])\n",
    "    \n",
    "    # Filter for touches and create alert\n",
    "    ema_touch_alerts = df.filter(pl.col(\"ema_touch_type\").is_not_null())\n",
    "    ema_touch_alerts = ema_touch_alerts.with_columns([\n",
    "        pl.lit(\"ema_touch\").alias(\"alert_type\"),\n",
    "        pl.col(\"ema_touch_type\").alias(\"signal\"),\n",
    "        pl.lit(interval).alias(\"interval\")\n",
    "    ])\n",
    "    \n",
    "    return ema_touch_alerts.select(\"symbol\", \"date\", \"interval\", \"alert_type\", \"signal\")\n",
    "\n",
    "# Step 4: Process all intervals and combine alerts\n",
    "all_alerts = []\n",
    "df_with_indicators = df_with_indicators.filter(pl.col(\"date\").dt.replace_time_zone(\"America/Edmonton\") >= pd.to_datetime(\"2020-01-01\").tz_localize(\"America/Edmonton\"))\n",
    "\n",
    "for interval in intervals:\n",
    "    df_interval = df_with_indicators.filter(pl.col(\"interval\") == interval)\n",
    "    \n",
    "    # Skip empty DataFrames\n",
    "    if df_interval.height == 0:\n",
    "        continue\n",
    "        \n",
    "    # Add velocity alerts\n",
    "    velocity_df = add_velocity_alert(df_interval)\n",
    "    velocity_alerts = velocity_df.with_columns([\n",
    "        pl.lit(\"velocity_alert\").alias(\"alert_type\"),\n",
    "        pl.col(\"velocity_status\").alias(\"signal\"),\n",
    "        pl.lit(interval).alias(\"interval\")\n",
    "    ]).select(\"symbol\", \"date\", \"interval\", \"alert_type\", \"signal\")\n",
    "    \n",
    "    # Add momentum alerts\n",
    "    momentum_alerts = add_accel_decel_alert(df_interval, interval)\n",
    "    \n",
    "    # Add EMA touch alerts\n",
    "    ema_touch_alerts = add_ema_touch_alert(df_interval, interval)\n",
    "    \n",
    "    # Combine all alerts for this interval\n",
    "    all_alerts.extend([\n",
    "        velocity_alerts,\n",
    "        momentum_alerts,\n",
    "        ema_touch_alerts\n",
    "    ])\n",
    "\n",
    "# Step 5: Combine all alerts into final DataFrame\n",
    "if all_alerts:\n",
    "    alert_df = pl.concat(all_alerts)\n",
    "else:\n",
    "    # Return empty DataFrame with correct schema if no alerts\n",
    "    alert_df = pl.DataFrame({\n",
    "        \"symbol\": [],\n",
    "        \"date\": [],\n",
    "        \"interval\": [],\n",
    "        \"alert_type\": [],\n",
    "        \"signal\": []\n",
    "    })\n",
    "\n",
    "# Print results for verification\n",
    "print(\"\\nFirst 10 rows of alerts:\")\n",
    "print(alert_df.head(10))\n",
    "\n",
    "# Filter specific alert types for analysis\n",
    "momentum_df = alert_df.filter(pl.col(\"alert_type\") == \"momentum_alert\")\n",
    "ema_df = alert_df.filter(pl.col(\"alert_type\") == \"ema_touch\")\n",
    "\n",
    "print(\"\\nFirst 5 momentum alerts:\")\n",
    "print(momentum_df.head())\n",
    "\n",
    "print(\"\\nFirst 5 EMA touch alerts:\")\n",
    "print(ema_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Add Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval weights: {1: 1, 3: 2, 5: 3, 8: 4, 13: 5}\n",
      "\n",
      "Momentum results:\n",
      "shape: (5, 4)\n",
      "┌────────┬──────────┬────────────────────────────┬────────────────────────────┐\n",
      "│ symbol ┆ interval ┆ momentum_alert_accelerated ┆ momentum_alert_decelerated │\n",
      "│ ---    ┆ ---      ┆ ---                        ┆ ---                        │\n",
      "│ str    ┆ i32      ┆ i32                        ┆ i32                        │\n",
      "╞════════╪══════════╪════════════════════════════╪════════════════════════════╡\n",
      "│ SURG   ┆ 1        ┆ 215                        ┆ 666                        │\n",
      "│ BPYPN  ┆ 5        ┆ 285                        ┆ 564                        │\n",
      "│ MRCY   ┆ 1        ┆ 285                        ┆ 586                        │\n",
      "│ RIVN   ┆ 3        ┆ 130                        ┆ 406                        │\n",
      "│ AMSF   ┆ 5        ┆ 311                        ┆ 544                        │\n",
      "└────────┴──────────┴────────────────────────────┴────────────────────────────┘\n",
      "\n",
      "EMA touch results:\n",
      "shape: (5, 5)\n",
      "┌────────┬──────────┬───────────────────────┬────────────────────┬───────┐\n",
      "│ symbol ┆ interval ┆ touch_type_resistance ┆ touch_type_support ┆ count │\n",
      "│ ---    ┆ ---      ┆ ---                   ┆ ---                ┆ ---   │\n",
      "│ str    ┆ i32      ┆ i32                   ┆ i32                ┆ u32   │\n",
      "╞════════╪══════════╪═══════════════════════╪════════════════════╪═══════╡\n",
      "│ DOCS   ┆ 3        ┆ 115                   ┆ 102                ┆ 299   │\n",
      "│ ACHV   ┆ 5        ┆ 354                   ┆ 225                ┆ 689   │\n",
      "│ HPQ    ┆ 5        ┆ 383                   ┆ 532                ┆ 1026  │\n",
      "│ JXG    ┆ 13       ┆ 434                   ┆ 338                ┆ 883   │\n",
      "│ ECPG   ┆ 13       ┆ 550                   ┆ 600                ┆ 1241  │\n",
      "└────────┴──────────┴───────────────────────┴────────────────────┴───────┘\n",
      "\n",
      "Combined micro results:\n",
      "shape: (5, 9)\n",
      "┌────────┬──────────┬─────────────┬─────────────┬───┬────────────┬────────────┬────────────┬───────┐\n",
      "│ symbol ┆ interval ┆ momentum_al ┆ momentum_al ┆ … ┆ interval_r ┆ touch_type ┆ touch_type ┆ count │\n",
      "│ ---    ┆ ---      ┆ ert_acceler ┆ ert_deceler ┆   ┆ ight       ┆ _resistanc ┆ _support   ┆ ---   │\n",
      "│ str    ┆ i32      ┆ ated        ┆ ated        ┆   ┆ ---        ┆ e          ┆ ---        ┆ u32   │\n",
      "│        ┆          ┆ ---         ┆ ---         ┆   ┆ i32        ┆ ---        ┆ i32        ┆       │\n",
      "│        ┆          ┆ i32         ┆ i32         ┆   ┆            ┆ i32        ┆            ┆       │\n",
      "╞════════╪══════════╪═════════════╪═════════════╪═══╪════════════╪════════════╪════════════╪═══════╡\n",
      "│ SURG   ┆ 1        ┆ 215         ┆ 666         ┆ … ┆ 1          ┆ 28         ┆ 38         ┆ 106   │\n",
      "│ BPYPN  ┆ 5        ┆ 285         ┆ 564         ┆ … ┆ 5          ┆ 452        ┆ 528        ┆ 1073  │\n",
      "│ MRCY   ┆ 1        ┆ 285         ┆ 586         ┆ … ┆ 1          ┆ 42         ┆ 55         ┆ 169   │\n",
      "│ RIVN   ┆ 3        ┆ 130         ┆ 406         ┆ … ┆ 3          ┆ 60         ┆ 81         ┆ 196   │\n",
      "│ AMSF   ┆ 5        ┆ 311         ┆ 544         ┆ … ┆ 5          ┆ 563        ┆ 539        ┆ 1238  │\n",
      "└────────┴──────────┴─────────────┴─────────────┴───┴────────────┴────────────┴────────────┴───────┘\n",
      "\n",
      "Micro results with weights:\n",
      "shape: (5, 10)\n",
      "┌────────┬──────────┬─────────────┬─────────────┬───┬────────────┬────────────┬───────┬────────────┐\n",
      "│ symbol ┆ interval ┆ momentum_al ┆ momentum_al ┆ … ┆ touch_type ┆ touch_type ┆ count ┆ interval_w │\n",
      "│ ---    ┆ ---      ┆ ert_acceler ┆ ert_deceler ┆   ┆ _resistanc ┆ _support   ┆ ---   ┆ eight      │\n",
      "│ str    ┆ i32      ┆ ated        ┆ ated        ┆   ┆ e          ┆ ---        ┆ u32   ┆ ---        │\n",
      "│        ┆          ┆ ---         ┆ ---         ┆   ┆ ---        ┆ i32        ┆       ┆ i64        │\n",
      "│        ┆          ┆ i32         ┆ i32         ┆   ┆ i32        ┆            ┆       ┆            │\n",
      "╞════════╪══════════╪═════════════╪═════════════╪═══╪════════════╪════════════╪═══════╪════════════╡\n",
      "│ SURG   ┆ 1        ┆ 215         ┆ 666         ┆ … ┆ 28         ┆ 38         ┆ 106   ┆ 1          │\n",
      "│ BPYPN  ┆ 5        ┆ 285         ┆ 564         ┆ … ┆ 452        ┆ 528        ┆ 1073  ┆ 3          │\n",
      "│ MRCY   ┆ 1        ┆ 285         ┆ 586         ┆ … ┆ 42         ┆ 55         ┆ 169   ┆ 1          │\n",
      "│ RIVN   ┆ 3        ┆ 130         ┆ 406         ┆ … ┆ 60         ┆ 81         ┆ 196   ┆ 2          │\n",
      "│ AMSF   ┆ 5        ┆ 311         ┆ 544         ┆ … ┆ 563        ┆ 539        ┆ 1238  ┆ 3          │\n",
      "└────────┴──────────┴─────────────┴─────────────┴───┴────────────┴────────────┴───────┴────────────┘\n",
      "\n",
      "Micro results with weighted values:\n",
      "shape: (5, 14)\n",
      "┌────────┬──────────┬────────────┬────────────┬───┬────────────┬───────────┬───────────┬───────────┐\n",
      "│ symbol ┆ interval ┆ momentum_a ┆ momentum_a ┆ … ┆ weighted_m ┆ weighted_ ┆ weighted_ ┆ weighted_ │\n",
      "│ ---    ┆ ---      ┆ lert_accel ┆ lert_decel ┆   ┆ omentum_al ┆ momentum_ ┆ touch_typ ┆ touch_typ │\n",
      "│ str    ┆ i32      ┆ erated     ┆ erated     ┆   ┆ ert_accele ┆ alert_dec ┆ e_resista ┆ e_support │\n",
      "│        ┆          ┆ ---        ┆ ---        ┆   ┆ …          ┆ ele…      ┆ nce       ┆ ---       │\n",
      "│        ┆          ┆ i32        ┆ i32        ┆   ┆ ---        ┆ ---       ┆ ---       ┆ i64       │\n",
      "│        ┆          ┆            ┆            ┆   ┆ i64        ┆ i64       ┆ i64       ┆           │\n",
      "╞════════╪══════════╪════════════╪════════════╪═══╪════════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ SURG   ┆ 1        ┆ 215        ┆ 666        ┆ … ┆ 215        ┆ 666       ┆ 28        ┆ 38        │\n",
      "│ BPYPN  ┆ 5        ┆ 285        ┆ 564        ┆ … ┆ 855        ┆ 1692      ┆ 1356      ┆ 1584      │\n",
      "│ MRCY   ┆ 1        ┆ 285        ┆ 586        ┆ … ┆ 285        ┆ 586       ┆ 42        ┆ 55        │\n",
      "│ RIVN   ┆ 3        ┆ 130        ┆ 406        ┆ … ┆ 260        ┆ 812       ┆ 120       ┆ 162       │\n",
      "│ AMSF   ┆ 5        ┆ 311        ┆ 544        ┆ … ┆ 933        ┆ 1632      ┆ 1689      ┆ 1617      │\n",
      "└────────┴──────────┴────────────┴────────────┴───┴────────────┴───────────┴───────────┴───────────┘\n",
      "\n",
      "Macro results:\n",
      "shape: (5, 5)\n",
      "┌────────┬──────────┬─────────────────────┬───────────────┬───────────────┐\n",
      "│ symbol ┆ interval ┆ velocity_maintained ┆ velocity_weak ┆ velocity_loss │\n",
      "│ ---    ┆ ---      ┆ ---                 ┆ ---           ┆ ---           │\n",
      "│ str    ┆ i32      ┆ i32                 ┆ i32           ┆ i32           │\n",
      "╞════════╪══════════╪═════════════════════╪═══════════════╪═══════════════╡\n",
      "│ AEI    ┆ 8        ┆ 104                 ┆ 106           ┆ 558           │\n",
      "│ SNDR   ┆ 3        ┆ 295                 ┆ 235           ┆ 409           │\n",
      "│ NVTS   ┆ 5        ┆ 146                 ┆ 94            ┆ 390           │\n",
      "│ ZLAB   ┆ 8        ┆ 266                 ┆ 222           ┆ 456           │\n",
      "│ MDBH   ┆ 1        ┆ 23                  ┆ 39            ┆ 202           │\n",
      "└────────┴──────────┴─────────────────────┴───────────────┴───────────────┘\n",
      "\n",
      "Macro results with weights:\n",
      "shape: (5, 6)\n",
      "┌────────┬──────────┬─────────────────────┬───────────────┬───────────────┬─────────────────┐\n",
      "│ symbol ┆ interval ┆ velocity_maintained ┆ velocity_weak ┆ velocity_loss ┆ interval_weight │\n",
      "│ ---    ┆ ---      ┆ ---                 ┆ ---           ┆ ---           ┆ ---             │\n",
      "│ str    ┆ i32      ┆ i32                 ┆ i32           ┆ i32           ┆ i64             │\n",
      "╞════════╪══════════╪═════════════════════╪═══════════════╪═══════════════╪═════════════════╡\n",
      "│ AEI    ┆ 8        ┆ 104                 ┆ 106           ┆ 558           ┆ 4               │\n",
      "│ SNDR   ┆ 3        ┆ 295                 ┆ 235           ┆ 409           ┆ 2               │\n",
      "│ NVTS   ┆ 5        ┆ 146                 ┆ 94            ┆ 390           ┆ 3               │\n",
      "│ ZLAB   ┆ 8        ┆ 266                 ┆ 222           ┆ 456           ┆ 4               │\n",
      "│ MDBH   ┆ 1        ┆ 23                  ┆ 39            ┆ 202           ┆ 1               │\n",
      "└────────┴──────────┴─────────────────────┴───────────────┴───────────────┴─────────────────┘\n",
      "\n",
      "Macro results with weighted values:\n",
      "shape: (5, 9)\n",
      "┌────────┬──────────┬────────────┬────────────┬───┬────────────┬───────────┬───────────┬───────────┐\n",
      "│ symbol ┆ interval ┆ velocity_m ┆ velocity_w ┆ … ┆ interval_w ┆ weighted_ ┆ weighted_ ┆ weighted_ │\n",
      "│ ---    ┆ ---      ┆ aintained  ┆ eak        ┆   ┆ eight      ┆ velocity_ ┆ velocity_ ┆ velocity_ │\n",
      "│ str    ┆ i32      ┆ ---        ┆ ---        ┆   ┆ ---        ┆ maintaine ┆ weak      ┆ loss      │\n",
      "│        ┆          ┆ i32        ┆ i32        ┆   ┆ i64        ┆ d         ┆ ---       ┆ ---       │\n",
      "│        ┆          ┆            ┆            ┆   ┆            ┆ ---       ┆ i64       ┆ i64       │\n",
      "│        ┆          ┆            ┆            ┆   ┆            ┆ i64       ┆           ┆           │\n",
      "╞════════╪══════════╪════════════╪════════════╪═══╪════════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ AEI    ┆ 8        ┆ 104        ┆ 106        ┆ … ┆ 4          ┆ 416       ┆ 424       ┆ 2232      │\n",
      "│ SNDR   ┆ 3        ┆ 295        ┆ 235        ┆ … ┆ 2          ┆ 590       ┆ 470       ┆ 818       │\n",
      "│ NVTS   ┆ 5        ┆ 146        ┆ 94         ┆ … ┆ 3          ┆ 438       ┆ 282       ┆ 1170      │\n",
      "│ ZLAB   ┆ 8        ┆ 266        ┆ 222        ┆ … ┆ 4          ┆ 1064      ┆ 888       ┆ 1824      │\n",
      "│ MDBH   ┆ 1        ┆ 23         ┆ 39         ┆ … ┆ 1          ┆ 23        ┆ 39        ┆ 202       │\n",
      "└────────┴──────────┴────────────┴────────────┴───┴────────────┴───────────┴───────────┴───────────┘\n",
      "\n",
      "Short accelerating stocks: ['EMP', 'EMP']\n",
      "\n",
      "Long accelerating stocks: ['EMP']\n",
      "\n",
      "Long accumulating stocks: ['MLAC', 'KVAC', 'JUNS', 'AZI', 'ALDF', 'AIFE', 'EURK', 'XHLD', 'MBAV', 'AAM']\n",
      "\n",
      "Velocity maintained stocks: ['EMP', 'EMP']\n",
      "\n",
      "Final results:\n",
      "shape: (1_341, 5)\n",
      "┌────────────────────┬────────────────┬───────────────────┬────────────────────┬───────────────────┐\n",
      "│ date               ┆ accelerating   ┆ long_accelerating ┆ long_accumulating  ┆ velocity_maintain │\n",
      "│ ---                ┆ ---            ┆ ---               ┆ ---                ┆ ed                │\n",
      "│ list[datetime[μs,  ┆ list[str]      ┆ list[str]         ┆ list[str]          ┆ ---               │\n",
      "│ America/Edmonton]] ┆                ┆                   ┆                    ┆ list[str]         │\n",
      "╞════════════════════╪════════════════╪═══════════════════╪════════════════════╪═══════════════════╡\n",
      "│ [2024-11-22        ┆ [\"EMP\", \"EMP\"] ┆ [\"EMP\"]           ┆ [\"MLAC\", \"KVAC\", … ┆ [\"EMP\", \"EMP\"]    │\n",
      "│ 00:00:00 MST]      ┆                ┆                   ┆ \"AAM\"]             ┆                   │\n",
      "│ [2024-12-03        ┆ [\"EMP\", \"EMP\"] ┆ [\"EMP\"]           ┆ [\"MLAC\", \"KVAC\", … ┆ [\"EMP\", \"EMP\"]    │\n",
      "│ 00:00:00 MST]      ┆                ┆                   ┆ \"AAM\"]             ┆                   │\n",
      "│ [2021-06-01        ┆ [\"EMP\", \"EMP\"] ┆ [\"EMP\"]           ┆ [\"MLAC\", \"KVAC\", … ┆ [\"EMP\", \"EMP\"]    │\n",
      "│ 00:00:00 MDT]      ┆                ┆                   ┆ \"AAM\"]             ┆                   │\n",
      "│ [2022-07-21        ┆ [\"EMP\", \"EMP\"] ┆ [\"EMP\"]           ┆ [\"MLAC\", \"KVAC\", … ┆ [\"EMP\", \"EMP\"]    │\n",
      "│ 00:00:00 MDT]      ┆                ┆                   ┆ \"AAM\"]             ┆                   │\n",
      "│ [2020-02-24        ┆ [\"EMP\", \"EMP\"] ┆ [\"EMP\"]           ┆ [\"MLAC\", \"KVAC\", … ┆ [\"EMP\", \"EMP\"]    │\n",
      "│ 00:00:00 MST]      ┆                ┆                   ┆ \"AAM\"]             ┆                   │\n",
      "│ …                  ┆ …              ┆ …                 ┆ …                  ┆ …                 │\n",
      "│ [2024-05-08        ┆ [\"EMP\", \"EMP\"] ┆ [\"EMP\"]           ┆ [\"MLAC\", \"KVAC\", … ┆ [\"EMP\", \"EMP\"]    │\n",
      "│ 00:00:00 MDT]      ┆                ┆                   ┆ \"AAM\"]             ┆                   │\n",
      "│ [2020-01-22        ┆ [\"EMP\", \"EMP\"] ┆ [\"EMP\"]           ┆ [\"MLAC\", \"KVAC\", … ┆ [\"EMP\", \"EMP\"]    │\n",
      "│ 00:00:00 MST]      ┆                ┆                   ┆ \"AAM\"]             ┆                   │\n",
      "│ [2021-08-19        ┆ [\"EMP\", \"EMP\"] ┆ [\"EMP\"]           ┆ [\"MLAC\", \"KVAC\", … ┆ [\"EMP\", \"EMP\"]    │\n",
      "│ 00:00:00 MDT]      ┆                ┆                   ┆ \"AAM\"]             ┆                   │\n",
      "│ [2020-11-24        ┆ [\"EMP\", \"EMP\"] ┆ [\"EMP\"]           ┆ [\"MLAC\", \"KVAC\", … ┆ [\"EMP\", \"EMP\"]    │\n",
      "│ 00:00:00 MST]      ┆                ┆                   ┆ \"AAM\"]             ┆                   │\n",
      "│ [2022-02-11        ┆ [\"EMP\", \"EMP\"] ┆ [\"EMP\"]           ┆ [\"MLAC\", \"KVAC\", … ┆ [\"EMP\", \"EMP\"]    │\n",
      "│ 00:00:00 MST]      ┆                ┆                   ┆ \"AAM\"]             ┆                   │\n",
      "└────────────────────┴────────────────┴───────────────────┴────────────────────┴───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize interval weights\n",
    "distinct_intervals = alert_df.get_column(\"interval\").unique().sort()\n",
    "interval_weights = {interval: weight for weight, interval in enumerate(distinct_intervals, 1)}\n",
    "print(\"Interval weights:\", interval_weights)\n",
    "\n",
    "# Step 2: Process momentum alerts for micro intervals\n",
    "momentum_data = alert_df.filter(pl.col(\"alert_type\") == \"momentum_alert\")\n",
    "momentum_results = momentum_data.group_by([\"symbol\", \"interval\"]).agg([\n",
    "    pl.when(pl.col(\"signal\") == \"accelerated\").then(1).otherwise(0).sum().alias(\"momentum_alert_accelerated\"),\n",
    "    pl.when(pl.col(\"signal\") == \"decelerated\").then(1).otherwise(0).sum().alias(\"momentum_alert_decelerated\")\n",
    "])\n",
    "print(\"\\nMomentum results:\")\n",
    "print(momentum_results.head())\n",
    "\n",
    "# Step 3: Process EMA touch alerts\n",
    "ema_data = alert_df.filter(pl.col(\"alert_type\") == \"ema_touch\")\n",
    "ema_results = ema_data.group_by([\"symbol\", \"interval\"]).agg([\n",
    "    pl.when(pl.col(\"signal\") == \"resistance\").then(1).otherwise(0).sum().alias(\"touch_type_resistance\"),\n",
    "    pl.when(pl.col(\"signal\") == \"support\").then(1).otherwise(0).sum().alias(\"touch_type_support\"),\n",
    "    pl.len().alias(\"count\")\n",
    "])\n",
    "print(\"\\nEMA touch results:\")\n",
    "print(ema_results.head())\n",
    "\n",
    "# Step 4: Join momentum and EMA results\n",
    "micro_results = momentum_results.join(\n",
    "    ema_results,\n",
    "    on=[\"symbol\", \"interval\"],\n",
    "    how=\"full\"\n",
    ").fill_null(0)\n",
    "print(\"\\nCombined micro results:\")\n",
    "print(micro_results.head())\n",
    "\n",
    "# Step 5: Apply interval weighting to micro results\n",
    "micro_results = micro_results.with_columns([\n",
    "    pl.col(\"interval\").map_elements(lambda x: interval_weights.get(x, 0), return_dtype=pl.Int64).alias(\"interval_weight\")\n",
    "])\n",
    "print(\"\\nMicro results with weights:\")\n",
    "print(micro_results.head())\n",
    "\n",
    "# Step 6: Calculate weighted values for micro results\n",
    "micro_results = micro_results.with_columns([\n",
    "    (pl.col(\"momentum_alert_accelerated\") * pl.col(\"interval_weight\")).alias(\"weighted_momentum_alert_accelerated\"),\n",
    "    (pl.col(\"momentum_alert_decelerated\") * pl.col(\"interval_weight\")).alias(\"weighted_momentum_alert_decelerated\"),\n",
    "    (pl.col(\"touch_type_resistance\") * pl.col(\"interval_weight\")).alias(\"weighted_touch_type_resistance\"),\n",
    "    (pl.col(\"touch_type_support\") * pl.col(\"interval_weight\")).alias(\"weighted_touch_type_support\")\n",
    "])\n",
    "print(\"\\nMicro results with weighted values:\")\n",
    "print(micro_results.head())\n",
    "\n",
    "# Step 7: Process velocity alerts for macro intervals\n",
    "velocity_data = alert_df.filter(pl.col(\"alert_type\") == \"velocity_alert\")\n",
    "macro_results = velocity_data.group_by([\"symbol\", \"interval\"]).agg([\n",
    "    pl.when(pl.col(\"signal\") == \"velocity_maintained\").then(1).otherwise(0).sum().alias(\"velocity_maintained\"),\n",
    "    pl.when(pl.col(\"signal\") == \"velocity_weak\").then(1).otherwise(0).sum().alias(\"velocity_weak\"),\n",
    "    pl.when(pl.col(\"signal\") == \"velocity_loss\").then(1).otherwise(0).sum().alias(\"velocity_loss\")\n",
    "])\n",
    "print(\"\\nMacro results:\")\n",
    "print(macro_results.head())\n",
    "\n",
    "# Step 8: Apply interval weighting to macro results\n",
    "macro_results = macro_results.with_columns([\n",
    "    pl.col(\"interval\").map_elements(lambda x: interval_weights.get(x, 0), return_dtype=pl.Int64).alias(\"interval_weight\")\n",
    "])\n",
    "print(\"\\nMacro results with weights:\")\n",
    "print(macro_results.head())\n",
    "\n",
    "# Step 9: Calculate weighted values for macro results\n",
    "macro_results = macro_results.with_columns([\n",
    "    (pl.col(\"velocity_maintained\") * pl.col(\"interval_weight\")).alias(\"weighted_velocity_maintained\"),\n",
    "    (pl.col(\"velocity_weak\") * pl.col(\"interval_weight\")).alias(\"weighted_velocity_weak\"),\n",
    "    (pl.col(\"velocity_loss\") * pl.col(\"interval_weight\")).alias(\"weighted_velocity_loss\")\n",
    "])\n",
    "print(\"\\nMacro results with weighted values:\")\n",
    "print(macro_results.head())\n",
    "\n",
    "# Step 10: Filter for specific stock categories\n",
    "short_acc_equ = micro_results.filter(\n",
    "    (pl.col(\"weighted_momentum_alert_accelerated\") > 1) &\n",
    "    (pl.col(\"weighted_momentum_alert_decelerated\") < 1) &\n",
    "    (pl.col(\"interval\") <= 3)\n",
    ").get_column(\"symbol\")\n",
    "\n",
    "lng_acc_equ = micro_results.filter(\n",
    "    (pl.col(\"weighted_momentum_alert_accelerated\") > 1) &\n",
    "    (pl.col(\"weighted_momentum_alert_decelerated\") < 1) &\n",
    "    (pl.col(\"interval\") == 5)\n",
    ").get_column(\"symbol\")\n",
    "\n",
    "lng_main_acc_equ = micro_results.filter(\n",
    "    (pl.col(\"weighted_touch_type_support\") > 1) &\n",
    "    (pl.col(\"weighted_touch_type_resistance\") < 1) &\n",
    "    (pl.col(\"count\") >= 1) &\n",
    "    (pl.col(\"interval\") == 5)\n",
    ").get_column(\"symbol\")\n",
    "\n",
    "maintained_stocks = macro_results.filter(\n",
    "    (pl.col(\"weighted_velocity_maintained\") > 0) &\n",
    "    (pl.col(\"weighted_velocity_weak\") == 0) &\n",
    "    (pl.col(\"weighted_velocity_loss\") == 0) &\n",
    "    (pl.col(\"interval\") >= 8)\n",
    ").get_column(\"symbol\")\n",
    "\n",
    "print(\"\\nShort accelerating stocks:\", short_acc_equ.to_list())\n",
    "print(\"\\nLong accelerating stocks:\", lng_acc_equ.to_list())\n",
    "print(\"\\nLong accumulating stocks:\", lng_main_acc_equ.to_list())\n",
    "print(\"\\nVelocity maintained stocks:\", maintained_stocks.to_list())\n",
    "\n",
    "# Step 11: Group results by date and create final DataFrame\n",
    "grouped_data = alert_df.group_by(\"date\")\n",
    "results = []\n",
    "\n",
    "for date, group in grouped_data:\n",
    "    micro_data = group.filter(pl.col(\"interval\") <= 5)\n",
    "    macro_data = group.filter(pl.col(\"interval\") >= 8)\n",
    "    \n",
    "    date_results = {\n",
    "        \"date\": date,\n",
    "        \"accelerating\": short_acc_equ.to_list(),\n",
    "        \"long_accelerating\": lng_acc_equ.to_list(),\n",
    "        \"long_accumulating\": lng_main_acc_equ.to_list(),\n",
    "        \"velocity_maintained\": maintained_stocks.to_list()\n",
    "    }\n",
    "    results.append(date_results)\n",
    "\n",
    "final_results = pl.DataFrame(results)\n",
    "print(\"\\nFinal results:\")\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, user: str, password: str, intervals: List[int]):\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.con = duckdb.connect()\n",
    "        self.intervals = intervals\n",
    "\n",
    "    def _get_resampled_data(self, interval: int) -> pd.DataFrame:\n",
    "        query = f\"\"\"\n",
    "        WITH raw_data AS (\n",
    "            SELECT * FROM postgres_scan(\n",
    "                'host=localhost port=5432 user={self.user} password={self.password} dbname=condvest',\n",
    "                'public', 'raw'\n",
    "            )\n",
    "        ),\n",
    "        ranked AS (\n",
    "            SELECT *,\n",
    "                row_number() OVER (PARTITION BY symbol ORDER BY date) as rn\n",
    "            FROM raw_data\n",
    "        ),\n",
    "        grouped AS (\n",
    "            SELECT *,\n",
    "                (rn - 1) / {interval} as group_id\n",
    "            FROM ranked\n",
    "        )\n",
    "        SELECT \n",
    "            symbol,\n",
    "            min(date) as date,\n",
    "            first(open) as open,\n",
    "            max(high) as high,\n",
    "            min(low) as low,\n",
    "            last(close) as close,\n",
    "            sum(volume) as volume,\n",
    "            '{interval}'::INT as interval\n",
    "        FROM grouped\n",
    "        GROUP BY symbol, group_id\n",
    "        ORDER BY symbol, date;\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.con.sql(query).df()\n",
    "\n",
    "    def load_data(self) -> pl.DataFrame:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Load and resample data for each interval\n",
    "        combined_results = []\n",
    "        for interval in self.intervals:\n",
    "            interval_start = time.time()\n",
    "            df = self._get_resampled_data(interval)\n",
    "            print(f\"DuckDB query execution time for interval {interval}: {time.time() - interval_start:.2f} seconds\")\n",
    "            combined_results.append(df)\n",
    "            print(f\"Duck to dataframe conversion time: {time.time() - interval_start:.2f} seconds\")\n",
    "\n",
    "        # Convert to Polars DataFrame\n",
    "        pl_resampled_df = pl.from_pandas(pd.concat(combined_results))\n",
    "        print(f\"Pandas to Polars conversion time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "        return pl_resampled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data Class\n",
    "data_loader = DataLoader(user=user, password=password, intervals=intervals)\n",
    "df = data_loader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicator Calculator Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndicatorCalculator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def add_indicators(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        df = df.sort(\"date\")\n",
    "        \n",
    "        # Compute EMAs\n",
    "        df = df.with_columns([\n",
    "            pl.col(\"close\").ewm_mean(span=8).alias(\"EMA_8\"),\n",
    "            pl.col(\"close\").ewm_mean(span=13).alias(\"EMA_13\"),\n",
    "            pl.col(\"close\").ewm_mean(span=21).alias(\"EMA_21\"),\n",
    "            pl.col(\"close\").ewm_mean(span=144).alias(\"EMA_144\"),\n",
    "            pl.col(\"close\").ewm_mean(span=169).alias(\"EMA_169\"),\n",
    "            pl.col(\"close\").ewm_mean(span=55).alias(\"EMA_55\"),\n",
    "            pl.col(\"close\").ewm_mean(span=89).alias(\"EMA_89\"),\n",
    "        ])\n",
    "        \n",
    "        # Compute MACD\n",
    "        df = df.with_columns([\n",
    "            (pl.col(\"EMA_13\") - pl.col(\"EMA_21\")).alias(\"macd_fast\"),\n",
    "            (pl.col(\"EMA_55\") - pl.col(\"EMA_89\")).alias(\"macd_slow\"),\n",
    "        ])\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def calculate_indicators(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Add indicators\n",
    "        df_with_indicators = df.group_by(\"symbol\", maintain_order=True).map_groups(self.add_indicators)\n",
    "        print(f\"Indicator calculation time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "        return df_with_indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate indicators\n",
    "indicator_calculator = IndicatorCalculator()\n",
    "results = indicator_calculator.calculate_indicators(df)\n",
    "print(\"\\nFirst 10 rows of result:\")\n",
    "print(results.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Alerts Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "class TrendAlertProcessor:\n",
    "    \"\"\"\n",
    "    TrendAlertProcessor using Polars for efficient processing of financial time series data.\n",
    "    Incorporates advanced trend detection algorithms from the dictionary-based implementation.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pl.DataFrame, intervals: List[int]):\n",
    "        self.df = df\n",
    "        self.intervals = intervals\n",
    "        self.rolling_window = 50\n",
    "    \n",
    "    def _add_velocity_alert(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Add velocity alerts based on the relationship between price and various EMAs.\n",
    "        Similar to velocity_alert_dict in the original implementation.\n",
    "        \"\"\"\n",
    "        # Add velocity status\n",
    "        df = df.with_columns([\n",
    "            pl.when(\n",
    "                (pl.col(\"close\") > pl.col(\"open\")) & \n",
    "                (pl.col(\"close\") > pl.max_horizontal(\"EMA_8\", \"EMA_13\")) & \n",
    "                (pl.col(\"close\") > pl.max_horizontal(\"EMA_144\", \"EMA_169\")) &\n",
    "                (pl.min_horizontal(\"EMA_8\", \"EMA_13\") > pl.max_horizontal(\"EMA_144\", \"EMA_169\"))\n",
    "            ).then(pl.lit(\"velocity_maintained\"))\n",
    "            .when(\n",
    "                (pl.col(\"close\") < pl.col(\"EMA_13\")) & \n",
    "                (pl.col(\"close\") > pl.col(\"EMA_169\"))\n",
    "            ).then(pl.lit(\"velocity_weak\"))\n",
    "            .when(\n",
    "                (pl.col(\"close\") < pl.col(\"EMA_13\")) & \n",
    "                (pl.col(\"close\") < pl.col(\"EMA_169\"))\n",
    "            ).then(pl.lit(\"velocity_loss\"))\n",
    "            .otherwise(pl.lit(\"velocity_negotiating\"))\n",
    "            .alias(\"velocity_status\")\n",
    "        ])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _add_accel_decel_alert(self, df: pl.DataFrame, interval: int) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Add acceleration/deceleration alerts based on EMA relationships and velocity status history.\n",
    "        \"\"\"\n",
    "        window_dict = {\n",
    "            1: 28, 3: 20, 5: 20, 8: 14, 13: 14\n",
    "        }\n",
    "        obs_window = window_dict.get(interval, 7)\n",
    "        \n",
    "        # First get velocity status\n",
    "        df = self._add_velocity_alert(df)\n",
    "        \n",
    "        # Count velocity statuses in the observation window\n",
    "        df = df.with_columns([\n",
    "            pl.col(\"velocity_status\").map_elements(\n",
    "                lambda s: 1 if s in [\"velocity_loss\", \"velocity_weak\", \"velocity_negotiating\"] else 0,\n",
    "                return_dtype=pl.Int32\n",
    "            ).alias(\"loss_flag\"),\n",
    "            pl.col(\"velocity_status\").map_elements(\n",
    "                lambda s: 1 if s == \"velocity_maintained\" else 0,\n",
    "                return_dtype=pl.Int32\n",
    "            ).alias(\"maintain_flag\")\n",
    "        ])\n",
    "        \n",
    "        df = df.with_columns([\n",
    "            pl.col(\"loss_flag\").rolling_sum(window_size=obs_window).alias(\"count_velocity_loss\"),\n",
    "            pl.col(\"maintain_flag\").rolling_sum(window_size=obs_window).alias(\"count_velocity_maintained\")\n",
    "        ])\n",
    "        \n",
    "        # Add acceleration/deceleration signals\n",
    "        df = df.with_columns([\n",
    "            pl.when(\n",
    "                (pl.max_horizontal(\"EMA_144\", \"EMA_169\") <= pl.max_horizontal(\"EMA_8\", \"EMA_13\")) &\n",
    "                (pl.col(\"open\") < pl.col(\"close\")) &\n",
    "                (pl.col(\"count_velocity_loss\") > pl.col(\"count_velocity_maintained\"))\n",
    "            ).then(pl.lit(\"accelerated\"))\n",
    "            .when(\n",
    "                (pl.col(\"close\") < pl.min_horizontal(\"EMA_8\", \"EMA_13\")) &\n",
    "                (pl.col(\"count_velocity_maintained\") < pl.col(\"count_velocity_loss\"))\n",
    "            ).then(pl.lit(\"decelerated\"))\n",
    "            .otherwise(None).alias(\"momentum_signal\")\n",
    "        ])\n",
    "        \n",
    "        # Create alert\n",
    "        momentum_alerts = df.filter(pl.col(\"momentum_signal\").is_not_null())\n",
    "        momentum_alerts = momentum_alerts.with_columns([\n",
    "            pl.lit(\"momentum_alert\").alias(\"alert_type\"),\n",
    "            pl.col(\"momentum_signal\").alias(\"signal\"),\n",
    "            pl.lit(interval).alias(\"interval\")\n",
    "        ])\n",
    "        \n",
    "        return momentum_alerts.select(\"symbol\", \"date\", \"interval\", \"alert_type\", \"signal\")\n",
    "    \n",
    "    def _add_ema_touch_alert(self, df: pl.DataFrame, interval: int) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Add alerts for when price touches or comes close to important EMAs.\n",
    "        \"\"\"\n",
    "        tolerance_dict = {\n",
    "            1: 0.002, 3: 0.02, 5: 0.05, 8: 0.07, 13: 0.1\n",
    "        }\n",
    "        tolerance = tolerance_dict.get(interval, 0.02)\n",
    "        \n",
    "        # Calculate tolerance bands around EMAs\n",
    "        df = df.with_columns([\n",
    "            pl.min_horizontal(\n",
    "                pl.col(\"EMA_144\"), pl.col(\"EMA_169\")\n",
    "            ).fill_null(pl.col(\"EMA_13\")).alias(\"long_term_min\"),\n",
    "            \n",
    "            pl.max_horizontal(\n",
    "                pl.col(\"EMA_144\"), pl.col(\"EMA_169\")\n",
    "            ).fill_null(pl.col(\"EMA_13\")).alias(\"long_term_max\"),\n",
    "            \n",
    "            pl.min_horizontal(\n",
    "                pl.col(\"EMA_8\"), pl.col(\"EMA_13\")\n",
    "            ).alias(\"short_term_min\"),\n",
    "            \n",
    "            pl.max_horizontal(\n",
    "                pl.col(\"EMA_8\"), pl.col(\"EMA_13\")\n",
    "            ).alias(\"short_term_max\")\n",
    "        ])\n",
    "        \n",
    "        # Calculate tolerance bands\n",
    "        df = df.with_columns([\n",
    "            (pl.col(\"long_term_min\") * (1 - tolerance)).alias(\"lower_bound\"),\n",
    "            (pl.col(\"long_term_max\") * (1 + tolerance)).alias(\"upper_bound\")\n",
    "        ])\n",
    "        \n",
    "        # Detect touches\n",
    "        df = df.with_columns([\n",
    "            pl.when(\n",
    "                ((pl.col(\"low\") <= pl.col(\"upper_bound\")) & (pl.col(\"low\") >= pl.col(\"lower_bound\"))) |\n",
    "                ((pl.col(\"EMA_13\") <= pl.col(\"upper_bound\")) & (pl.col(\"EMA_13\") >= pl.col(\"lower_bound\"))) |\n",
    "                ((pl.col(\"EMA_8\") <= pl.col(\"upper_bound\")) & (pl.col(\"EMA_8\") >= pl.col(\"lower_bound\")))\n",
    "            ).then(\n",
    "                pl.when(\n",
    "                    (pl.col(\"short_term_min\") > pl.col(\"long_term_max\")) &\n",
    "                    (pl.min_horizontal(pl.col(\"close\"), pl.col(\"open\")) > pl.col(\"long_term_min\"))\n",
    "                ).then(pl.lit(\"support\"))\n",
    "                .when(\n",
    "                    (pl.col(\"short_term_max\") < pl.col(\"long_term_max\")) &\n",
    "                    (pl.col(\"close\") < pl.col(\"long_term_max\"))\n",
    "                ).then(pl.lit(\"resistance\"))\n",
    "                .otherwise(pl.lit(\"neutral\"))\n",
    "            ).otherwise(None).alias(\"ema_touch_type\")\n",
    "        ])\n",
    "        \n",
    "        # Filter for touches and create alert\n",
    "        ema_touch_alerts = df.filter(pl.col(\"ema_touch_type\").is_not_null())\n",
    "        ema_touch_alerts = ema_touch_alerts.with_columns([\n",
    "            pl.lit(\"ema_touch\").alias(\"alert_type\"),\n",
    "            pl.col(\"ema_touch_type\").alias(\"signal\"),\n",
    "            pl.lit(interval).alias(\"interval\")\n",
    "        ])\n",
    "        \n",
    "        return ema_touch_alerts.select(\"symbol\", \"date\", \"interval\", \"alert_type\", \"signal\")\n",
    "    \n",
    "    def apply(self) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Apply all alert detection algorithms and return a combined DataFrame of alerts.\n",
    "        \"\"\"\n",
    "        all_alerts = []\n",
    "        \n",
    "        for interval in self.intervals:\n",
    "            df_interval = self.df.filter(pl.col(\"interval\") == interval)\n",
    "            \n",
    "            # No empty DataFrames\n",
    "            if df_interval.height == 0:\n",
    "                continue\n",
    "                \n",
    "            # Add velocity alerts\n",
    "            velocity_df = self._add_velocity_alert(df_interval)\n",
    "            velocity_alerts = velocity_df.with_columns([\n",
    "                pl.lit(\"velocity_alert\").alias(\"alert_type\"),\n",
    "                pl.col(\"velocity_status\").alias(\"signal\"),\n",
    "                pl.lit(interval).alias(\"interval\")\n",
    "            ]).select(\"symbol\", \"date\", \"interval\", \"alert_type\", \"signal\")\n",
    "            \n",
    "            # Add momentum alerts\n",
    "            momentum_alerts = self._add_accel_decel_alert(df_interval, interval)\n",
    "            \n",
    "            # Add EMA touch alerts\n",
    "            ema_touch_alerts = self._add_ema_touch_alert(df_interval, interval)\n",
    "            \n",
    "            # Combine all alerts for this interval\n",
    "            all_alerts.extend([\n",
    "                velocity_alerts,\n",
    "                momentum_alerts,\n",
    "                ema_touch_alerts\n",
    "            ])\n",
    "        \n",
    "        # Combine all alerts into a single DataFrame\n",
    "        if all_alerts:\n",
    "            return pl.concat(all_alerts)\n",
    "        else:\n",
    "            # Return empty DataFrame with correct schema if no alerts\n",
    "            return pl.DataFrame({\n",
    "                \"symbol\": [],\n",
    "                \"date\": [],\n",
    "                \"interval\": [],\n",
    "                \"alert_type\": [],\n",
    "                \"signal\": []\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Signal Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockCandidatesProcessor:\n",
    "    \"\"\"\n",
    "    A class to process and analyze stock candidates using Polars for efficient data processing.\n",
    "    Analyzes stocks based on various criteria and alerts from different time intervals.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pl.DataFrame):\n",
    "        self.df = df\n",
    "        self.interval_weights = None\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize interval weights based on unique intervals in the data.\"\"\"\n",
    "        distinct_intervals = self.df.get_column(\"interval\").unique().sort()\n",
    "        self.interval_weights = {interval: weight for weight, interval in enumerate(distinct_intervals, 1)}\n",
    "        \n",
    "    def _evaluate_micro_interval_stocks(self, data: pl.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        Evaluate stocks based on micro-interval criteria (intervals <= 5).\n",
    "        Analyzes acceleration and accumulation patterns.\n",
    "        \"\"\"\n",
    "        # Process momentum alerts\n",
    "        momentum_data = data.filter(pl.col(\"alert_type\") == \"momentum_alert\")\n",
    "        momentum_results = momentum_data.group_by([\"symbol\", \"interval\"]).agg([\n",
    "            pl.when(pl.col(\"signal\") == \"accelerated\").then(1).otherwise(0).sum().alias(\"momentum_alert_accelerated\"),\n",
    "            pl.when(pl.col(\"signal\") == \"decelerated\").then(1).otherwise(0).sum().alias(\"momentum_alert_decelerated\")\n",
    "        ])\n",
    "        \n",
    "        # Process EMA touch alerts\n",
    "        ema_data = data.filter(pl.col(\"alert_type\") == \"ema_touch\")\n",
    "        ema_results = ema_data.group_by([\"symbol\", \"interval\"]).agg([\n",
    "            pl.when(pl.col(\"signal\") == \"resistance\").then(1).otherwise(0).sum().alias(\"touch_type_resistance\"),\n",
    "            pl.when(pl.col(\"signal\") == \"support\").then(1).otherwise(0).sum().alias(\"touch_type_support\"),\n",
    "            pl.len().alias(\"count\")\n",
    "        ])\n",
    "        \n",
    "        # Join the results\n",
    "        results = momentum_results.join(\n",
    "            ema_results,\n",
    "            on=[\"symbol\", \"interval\"],\n",
    "            how=\"full\"\n",
    "        ).fill_null(0)\n",
    "        \n",
    "        # Apply interval weighting\n",
    "        results = results.with_columns([\n",
    "            pl.col(\"interval\").map_elements(lambda x: self.interval_weights.get(x, 0), return_dtype=pl.Int64).alias(\"interval_weight\")\n",
    "        ])\n",
    "        \n",
    "        # Calculate weighted values\n",
    "        results = results.with_columns([\n",
    "            (pl.col(\"momentum_alert_accelerated\") * pl.col(\"interval_weight\")).alias(\"weighted_momentum_alert_accelerated\"),\n",
    "            (pl.col(\"momentum_alert_decelerated\") * pl.col(\"interval_weight\")).alias(\"weighted_momentum_alert_decelerated\"),\n",
    "            (pl.col(\"touch_type_resistance\") * pl.col(\"interval_weight\")).alias(\"weighted_touch_type_resistance\"),\n",
    "            (pl.col(\"touch_type_support\") * pl.col(\"interval_weight\")).alias(\"weighted_touch_type_support\")\n",
    "        ])\n",
    "        \n",
    "        # Filter for accelerating stocks\n",
    "        short_acc_equ = results.filter(\n",
    "            (pl.col(\"weighted_momentum_alert_accelerated\") > 1) &\n",
    "            (pl.col(\"weighted_momentum_alert_decelerated\") < 1) &\n",
    "            (pl.col(\"interval\") <= 3)\n",
    "        ).get_column(\"symbol\")\n",
    "        \n",
    "        lng_acc_equ = results.filter(\n",
    "            (pl.col(\"weighted_momentum_alert_accelerated\") > 1) &\n",
    "            (pl.col(\"weighted_momentum_alert_decelerated\") < 1) &\n",
    "            (pl.col(\"interval\") == 5)\n",
    "        ).get_column(\"symbol\")\n",
    "        \n",
    "        lng_main_acc_equ = results.filter(\n",
    "            (pl.col(\"weighted_touch_type_support\") > 1) &\n",
    "            (pl.col(\"weighted_touch_type_resistance\") < 1) &\n",
    "            (pl.col(\"count\") >= 1) &\n",
    "            (pl.col(\"interval\") == 5)\n",
    "        ).get_column(\"symbol\")\n",
    "        \n",
    "        return {\n",
    "            \"accelerating\": short_acc_equ.to_list(),\n",
    "            \"long_accelerating\": lng_acc_equ.to_list(),\n",
    "            \"long_accumulating\": lng_main_acc_equ.to_list()\n",
    "        }\n",
    "\n",
    "    def _evaluate_macro_interval_stocks(self, data: pl.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        Evaluate stocks based on macro-interval criteria (intervals >= 8).\n",
    "        Analyzes velocity maintenance patterns.\n",
    "        \"\"\"\n",
    "        # Process velocity alerts\n",
    "        velocity_data = data.filter(pl.col(\"alert_type\") == \"velocity_alert\")\n",
    "        results = velocity_data.group_by([\"symbol\", \"interval\"]).agg([\n",
    "            pl.when(pl.col(\"signal\") == \"velocity_maintained\").then(1).otherwise(0).sum().alias(\"velocity_maintained\"),\n",
    "            pl.when(pl.col(\"signal\") == \"velocity_weak\").then(1).otherwise(0).sum().alias(\"velocity_weak\"),\n",
    "            pl.when(pl.col(\"signal\") == \"velocity_loss\").then(1).otherwise(0).sum().alias(\"velocity_loss\")\n",
    "        ])\n",
    "        \n",
    "        # Apply interval weighting\n",
    "        results = results.with_columns([\n",
    "        pl.col(\"interval\").map_elements(lambda x: self.interval_weights.get(x, 0), return_dtype=pl.Int64).alias(\"interval_weight\")\n",
    "        ])\n",
    "        \n",
    "        # Calculate weighted values\n",
    "        results = results.with_columns([\n",
    "            (pl.col(\"velocity_maintained\") * pl.col(\"interval_weight\")).alias(\"weighted_velocity_maintained\"),\n",
    "            (pl.col(\"velocity_weak\") * pl.col(\"interval_weight\")).alias(\"weighted_velocity_weak\"),\n",
    "            (pl.col(\"velocity_loss\") * pl.col(\"interval_weight\")).alias(\"weighted_velocity_loss\")\n",
    "        ])\n",
    "        \n",
    "        # Filter for maintained velocity stocks\n",
    "        maintained_stocks = results.filter(\n",
    "            (pl.col(\"weighted_velocity_maintained\") > 0) &\n",
    "            (pl.col(\"weighted_velocity_weak\") == 0) &\n",
    "            (pl.col(\"weighted_velocity_loss\") == 0) &\n",
    "            (pl.col(\"interval\") >= 8)\n",
    "        ).get_column(\"symbol\")\n",
    "        \n",
    "        return {\n",
    "            \"velocity_maintained\": maintained_stocks.to_list()\n",
    "        }\n",
    "\n",
    "    def process(self) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Process the data and generate stock candidates for each date.\n",
    "        Returns a DataFrame with the results.\n",
    "        \"\"\"\n",
    "        # Group data by date\n",
    "        grouped_data = self.df.group_by(\"date\")\n",
    "        \n",
    "        # Process candidates for each date\n",
    "        results = []\n",
    "        \n",
    "        for date, group in grouped_data:\n",
    "            # Process micro-interval data\n",
    "            micro_data = group.filter(pl.col(\"interval\") <= 5)\n",
    "            micro_results = self._evaluate_micro_interval_stocks(micro_data)\n",
    "            \n",
    "            # Process macro-interval data\n",
    "            macro_data = group.filter(pl.col(\"interval\") >= 8)\n",
    "            macro_results = self._evaluate_macro_interval_stocks(macro_data)\n",
    "            \n",
    "            # Combine results\n",
    "            combined_results = {**micro_results, **macro_results}\n",
    "            combined_results[\"date\"] = date\n",
    "            \n",
    "            results.append(combined_results)\n",
    "        \n",
    "        # Convert results to DataFrame\n",
    "        return pl.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completed OLAP Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB query execution time for interval 1: 21.64 seconds\n",
      "Duck to dataframe conversion time: 21.64 seconds\n",
      "DuckDB query execution time for interval 3: 15.07 seconds\n",
      "Duck to dataframe conversion time: 15.07 seconds\n",
      "DuckDB query execution time for interval 5: 14.41 seconds\n",
      "Duck to dataframe conversion time: 14.41 seconds\n",
      "DuckDB query execution time for interval 8: 14.69 seconds\n",
      "Duck to dataframe conversion time: 14.69 seconds\n",
      "DuckDB query execution time for interval 13: 14.49 seconds\n",
      "Duck to dataframe conversion time: 14.49 seconds\n",
      "Pandas to Polars conversion time: 98.89 seconds\n",
      "Indicator calculation time: 16.13 seconds\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and preprocess data\n",
    "data_loader = DataLoader(user=user, password=password, intervals=[1, 3, 5, 8, 13])\n",
    "df = data_loader.load_data()\n",
    "\n",
    "# Step 2: Calculate indicators\n",
    "indicator_calculator = IndicatorCalculator()\n",
    "df_with_indicators = indicator_calculator.calculate_indicators(df)\n",
    "\n",
    "# Step 3: Add alerts\n",
    "df_with_indicators = df_with_indicators.filter(pl.col(\"date\").dt.replace_time_zone(\"America/Edmonton\") >= pd.to_datetime(\"2020-01-01\").tz_localize(\"America/Edmonton\"))\n",
    "trend_alert = TrendAlertProcessor(df_with_indicators, intervals=[1, 3, 5, 8, 13])\n",
    "alert_df = trend_alert.apply()\n",
    "\n",
    "# Step 4: Add signals\n",
    "stock_candidates = StockCandidatesProcessor(alert_df)\n",
    "results_df = stock_candidates.process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort(\"date\", descending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
