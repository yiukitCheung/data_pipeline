{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import yfinance as yf\n",
    "import polygon \n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the timescaledb database\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get the postgres url\n",
    "postgres_url = os.environ.get('POSTGRES_URL')\n",
    "user = os.environ.get('POSTGRES_USER')\n",
    "password = os.environ.get('POSTGRES_PASSWORD')\n",
    "# Connect to the postgres database\n",
    "try:\n",
    "    conn = psycopg2.connect(postgres_url)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Connected to the timescaledb database\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to the database: {e}\")\n",
    "    conn = None\n",
    "    cursor = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect DuckDB to Timescale Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect Polar to Timescale Postgres\n",
    "duck_query = duckdb.sql(f\"\"\"\n",
    "    INSTALL postgres_scanner;\n",
    "    LOAD postgres_scanner;\n",
    "\n",
    "    SELECT * FROM postgres_scan(\n",
    "        'host=localhost port=5432 user={user} password={password} dbname=condvest',\n",
    "        'public', 'raw'\n",
    "    ) ORDER BY symbol, date DESC;\n",
    "\"\"\")\n",
    "\n",
    "duck_df = duck_query.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.1 ms, sys: 1.72 ms, total: 2.82 ms\n",
      "Wall time: 30.9 ms\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "WITH raw_data AS (\n",
    "    SELECT * FROM postgres_scan(\n",
    "        'host=localhost port=5432 user={user} password={password} dbname=condvest',\n",
    "        'public', 'raw' \n",
    "    )\n",
    "),\n",
    "ranked AS (\n",
    "    SELECT *,\n",
    "        row_number() OVER (PARTITION BY symbol ORDER BY date) as rn\n",
    "    FROM raw_data\n",
    "),\n",
    "grouped AS (\n",
    "    SELECT *,\n",
    "        (rn - 1) / 3 as group_id\n",
    "    FROM ranked\n",
    ")\n",
    "SELECT \n",
    "    symbol,\n",
    "    min(date) as date,\n",
    "    first(open) as open,\n",
    "    max(high) as high,\n",
    "    min(low) as low,\n",
    "    last(close) as close,\n",
    "    sum(volume) as volume\n",
    "FROM grouped\n",
    "GROUP BY symbol, group_id\n",
    "ORDER BY symbol, date;\n",
    "\"\"\"\n",
    "\n",
    "%time duckdb_result = duckdb.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────┬──────────────────────────┬───────────────┬───────────────┬───────────────┬───────────────┬────────────┐\n",
      "│ symbol  │           date           │     open      │     high      │      low      │     close     │   volume   │\n",
      "│ varchar │ timestamp with time zone │    double     │    double     │    double     │    double     │   double   │\n",
      "├─────────┼──────────────────────────┼───────────────┼───────────────┼───────────────┼───────────────┼────────────┤\n",
      "│ A       │ 1999-11-18 00:00:00-07   │ 27.3574259464 │ 30.0631082545 │ 24.0504850003 │ 26.4555339813 │ 62546380.0 │\n",
      "│ A       │ 1999-11-19 00:00:00-07   │ 25.8166832386 │ 25.8542633938 │ 23.9377412114 │ 24.2759513855 │ 15234146.0 │\n",
      "│ A       │ 1999-11-22 00:00:00-07   │ 24.8396412713 │ 26.4555339813 │  24.088063565 │ 26.4555339813 │  6577870.0 │\n",
      "│ A       │ 1999-11-23 00:00:00-07   │ 25.5536329556 │ 26.2300533352 │ 24.0504779816 │ 24.0504779816 │  5975611.0 │\n",
      "│ A       │ 1999-11-24 00:00:00-07   │ 24.1256402274 │  25.215428064 │ 24.0504815058 │ 24.6893234253 │  4843231.0 │\n",
      "│ A       │ 1999-11-26 00:00:00-07   │ 24.5765824054 │ 24.9523711468 │ 24.5014252984 │ 24.7644767761 │  1729466.0 │\n",
      "│ A       │ 1999-11-29 00:00:00-07   │ 24.6517461438 │ 25.5160594633 │ 24.3886930092 │ 25.3281650543 │  4074751.0 │\n",
      "│ A       │ 1999-11-30 00:00:00-07   │ 25.2530082491 │ 25.8166915191 │ 24.6141678512 │ 25.3657455444 │  4310034.0 │\n",
      "│ A       │ 1999-12-01 00:00:00-07   │  25.365744489 │  26.117322151 │ 25.1778500736 │ 25.8166904449 │  2957329.0 │\n",
      "│ A       │ 1999-12-02 00:00:00-07   │ 26.3052181553 │ 27.0567974659 │ 25.9670078663 │ 26.5306911469 │  3069868.0 │\n",
      "│ ·       │           ·              │        ·      │        ·      │         ·     │        ·      │       ·    │\n",
      "│ ·       │           ·              │        ·      │        ·      │         ·     │        ·      │       ·    │\n",
      "│ ·       │           ·              │        ·      │        ·      │         ·     │        ·      │       ·    │\n",
      "│ AA      │ 1976-05-04 00:00:00-06   │  2.5058753977 │  2.5616993904 │    2.46865935 │  2.5616993904 │   201748.0 │\n",
      "│ AA      │ 1976-05-05 00:00:00-06   │  2.5616979592 │  2.5679004991 │  2.5306847873 │  2.5492925644 │   170454.0 │\n",
      "│ AA      │ 1976-05-06 00:00:00-06   │   2.549290891 │  2.5616962777 │  2.5306831261 │  2.5430881977 │   300957.0 │\n",
      "│ AA      │ 1976-05-07 00:00:00-06   │  2.5430895496 │  2.5616976395 │  2.5182790782 │  2.5554947853 │   372201.0 │\n",
      "│ AA      │ 1976-05-10 00:00:00-06   │  2.5722285727 │  2.6034449785 │  2.5597421055 │  2.5972018242 │   348897.0 │\n",
      "│ AA      │ 1976-05-11 00:00:00-06   │  2.5972007094 │  2.6221737916 │  2.5722274686 │   2.603443861 │   363546.0 │\n",
      "│ AA      │ 1976-05-12 00:00:00-06   │  2.6096877113 │  2.6471474194 │  2.6096877113 │  2.6409039497 │   248356.0 │\n",
      "│ AA      │ 1976-05-13 00:00:00-06   │  2.6409032284 │  2.6783630848 │  2.6409032284 │  2.6783630848 │   465418.0 │\n",
      "│ AA      │ 1976-05-14 00:00:00-06   │  2.6783627675 │  2.6846059176 │  2.6346597654 │  2.6658761501 │   371536.0 │\n",
      "│ AA      │ 1976-05-17 00:00:00-06   │  2.6596330035 │  2.6596330035 │   2.634660083 │  2.6471467018 │   358219.0 │\n",
      "├─────────┴──────────────────────────┴───────────────┴───────────────┴───────────────┴───────────────┴────────────┤\n",
      "│ ? rows (>9999 rows, 20 shown)                                                                         7 columns │\n",
      "└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "duckdb_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect Polar to Timescale Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "required package 'connectorx' not found.\nPlease install using the command `pip install connectorx`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpolars\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load from Timescale using ConnectorX\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m polars_df \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_database_uri\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSELECT date, symbol, open, high, low, close, volume FROM raw ORDER BY symbol ASC, date ASC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpostgres_url\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/condvest/data_pipeline/.dp/lib/python3.10/site-packages/polars/io/database/functions.py:435\u001b[0m, in \u001b[0;36mread_database_uri\u001b[0;34m(query, uri, partition_on, partition_range, partition_num, protocol, engine, schema_overrides, execute_options)\u001b[0m\n\u001b[1;32m    433\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconnectorx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m engine does not support use of `execute_options`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_sql_connectorx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madbc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(query, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/Projects/condvest/data_pipeline/.dp/lib/python3.10/site-packages/polars/io/database/_utils.py:36\u001b[0m, in \u001b[0;36m_read_sql_connectorx\u001b[0;34m(query, connection_uri, partition_on, partition_range, partition_num, protocol, schema_overrides)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_sql_connectorx\u001b[39m(\n\u001b[1;32m     28\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m     29\u001b[0m     connection_uri: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     schema_overrides: SchemaDict \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m---> 36\u001b[0m     cx \u001b[38;5;241m=\u001b[39m \u001b[43mimport_optional\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconnectorx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         return_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marrow2\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m parse_version(cx\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marrow\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Projects/condvest/data_pipeline/.dp/lib/python3.10/site-packages/polars/dependencies.py:293\u001b[0m, in \u001b[0;36mimport_optional\u001b[0;34m(module_name, err_prefix, err_suffix, min_version, min_err_prefix, install_message)\u001b[0m\n\u001b[1;32m    288\u001b[0m     suffix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_suffix\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err_suffix \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m     err_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m    290\u001b[0m         install_message\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install using the command `pip install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m     )\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(err_message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m min_version:\n\u001b[1;32m    296\u001b[0m     min_version \u001b[38;5;241m=\u001b[39m parse_version(min_version)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: required package 'connectorx' not found.\nPlease install using the command `pip install connectorx`."
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Load from Timescale using ConnectorX\n",
    "polars_df = pl.read_database_uri(\n",
    "    \"SELECT date, symbol, open, high, low, close, volume FROM raw ORDER BY symbol ASC, date ASC\",\n",
    "    uri=postgres_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure datetime column is properly cast\n",
    "polars_df = polars_df.with_columns([\n",
    "    pl.col(\"date\").cast(pl.Datetime(\"us\"))\n",
    "])\n",
    "\n",
    "# Resample to 3-day OHLCV candles using Polars' groupby_dynamic\n",
    "resampled_3d_df = (\n",
    "    polars_df.group_by_dynamic(\n",
    "        index_column=\"date\",\n",
    "        every=\"3d\",\n",
    "        by=\"symbol\",\n",
    "        closed=\"left\",\n",
    "        period=\"3d\"\n",
    "    )\n",
    "    .agg([\n",
    "        pl.col(\"open\").first().alias(\"open\"),\n",
    "        pl.col(\"high\").max().alias(\"high\"),\n",
    "        pl.col(\"low\").min().alias(\"low\"),\n",
    "        pl.col(\"close\").last().alias(\"close\"),\n",
    "        pl.col(\"volume\").sum().alias(\"volume\")\n",
    "    ])\n",
    "    .sort([\"symbol\", \"date\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_3d_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DuckDB + Polar Add Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB query execution time: 0.03 seconds\n",
      "Duck to dataframe conversion time: 13.11 seconds\n",
      "DuckDB query execution time: 0.03 seconds\n",
      "Duck to dataframe conversion time: 15.00 seconds\n",
      "DuckDB query execution time: 0.03 seconds\n",
      "Duck to dataframe conversion time: 15.35 seconds\n",
      "DuckDB query execution time: 0.05 seconds\n",
      "Duck to dataframe conversion time: 14.76 seconds\n",
      "DuckDB query execution time: 0.03 seconds\n",
      "Duck to dataframe conversion time: 16.36 seconds\n",
      "Pandas to Polars conversion time: 17.89 seconds\n",
      "Indicator calculation time: 21.27 seconds\n",
      "\n",
      "First 10 rows of result:\n",
      "shape: (10, 17)\n",
      "┌────────┬─────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ symbol ┆ date        ┆ open      ┆ high      ┆ … ┆ EMA_55    ┆ EMA_89    ┆ macd_fast ┆ macd_slow │\n",
      "│ ---    ┆ ---         ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
      "│ str    ┆ datetime[μs ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
      "│        ┆ , America/E ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ dmonton]    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "╞════════╪═════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ A      ┆ 1999-11-18  ┆ 27.357426 ┆ 30.063108 ┆ … ┆ 26.455534 ┆ 26.455534 ┆ 0.0       ┆ 0.0       │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-18  ┆ 27.357426 ┆ 30.063108 ┆ … ┆ 26.455534 ┆ 26.455534 ┆ 0.0       ┆ 0.0       │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-18  ┆ 27.357426 ┆ 30.063108 ┆ … ┆ 26.455534 ┆ 26.455534 ┆ 0.0       ┆ 0.0       │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-18  ┆ 27.357426 ┆ 30.063108 ┆ … ┆ 26.455534 ┆ 26.455534 ┆ 0.0       ┆ 0.0       │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-18  ┆ 27.357426 ┆ 30.063108 ┆ … ┆ 26.455534 ┆ 26.455534 ┆ 0.0       ┆ 0.0       │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-19  ┆ 25.816683 ┆ 25.854263 ┆ … ┆ 26.058461 ┆ 26.07156  ┆ -0.061045 ┆ -0.013099 │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-19  ┆ 25.816683 ┆ 25.854263 ┆ … ┆ 25.775212 ┆ 25.797431 ┆ -0.099039 ┆ -0.022219 │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-19  ┆ 25.816683 ┆ 25.854263 ┆ … ┆ 25.563102 ┆ 25.591956 ┆ -0.122818 ┆ -0.028853 │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-19  ┆ 25.816683 ┆ 25.854263 ┆ … ┆ 25.398418 ┆ 25.432249 ┆ -0.137312 ┆ -0.033831 │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ A      ┆ 1999-11-19  ┆ 25.816683 ┆ 25.854263 ┆ … ┆ 25.266932 ┆ 25.30458  ┆ -0.145489 ┆ -0.037648 │\n",
      "│        ┆ 00:00:00    ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│        ┆ MST         ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "└────────┴─────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import polars as pl\n",
    "import time\n",
    "\n",
    "# Step 1: Connect and load Postgres data into DuckDB\n",
    "con = duckdb.connect()\n",
    "\n",
    "combined_results = []\n",
    "intervals = [1,3,5,8,13]\n",
    "for interval in intervals:\n",
    "    start_time = time.time()\n",
    "\n",
    "    query = f\"\"\"\n",
    "    WITH raw_data AS (\n",
    "        SELECT * FROM postgres_scan(\n",
    "            'host=localhost port=5432 user={user} password={password} dbname=condvest',\n",
    "            'public', 'raw'\n",
    "        )\n",
    "    ),\n",
    "    ranked AS (\n",
    "        SELECT *,\n",
    "            row_number() OVER (PARTITION BY symbol ORDER BY date) as rn\n",
    "        FROM raw_data\n",
    "    ),\n",
    "    grouped AS (\n",
    "        SELECT *,\n",
    "            (rn - 1) / {interval} as group_id\n",
    "        FROM ranked\n",
    "    )\n",
    "    SELECT \n",
    "        symbol,\n",
    "        min(date) as date,\n",
    "        first(open) as open,\n",
    "        max(high) as high,\n",
    "        min(low) as low,\n",
    "        last(close) as close,\n",
    "        sum(volume) as volume,\n",
    "        '{interval}'::INT as interval\n",
    "    FROM grouped\n",
    "    GROUP BY symbol, group_id\n",
    "    ORDER BY symbol, date;\n",
    "    \"\"\"\n",
    "    \n",
    "    df = duckdb.sql(query)\n",
    "    print(f\"DuckDB query execution time: {time.time() - start_time:.2f} seconds\")\n",
    "    combined_results.append(df.df())\n",
    "    print(f\"Duck to dataframe conversion time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Step 2: Convert to Polars DataFrame\n",
    "start_time = time.time()\n",
    "pl_resampled_df = pl.from_pandas(pd.concat(combined_results))\n",
    "print(f\"Pandas to Polars conversion time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Step 3: Convert to Polars and add indicators\n",
    "def add_indicators(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    df = df.sort(\"date\")\n",
    "    \n",
    "    # Step 1: Compute EMAs\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"close\").ewm_mean(span=8).alias(\"EMA_8\"),\n",
    "        pl.col(\"close\").ewm_mean(span=13).alias(\"EMA_13\"),\n",
    "        pl.col(\"close\").ewm_mean(span=21).alias(\"EMA_21\"),\n",
    "        pl.col(\"close\").ewm_mean(span=144).alias(\"EMA_144\"),\n",
    "        pl.col(\"close\").ewm_mean(span=169).alias(\"EMA_169\"),\n",
    "        pl.col(\"close\").ewm_mean(span=55).alias(\"EMA_55\"),\n",
    "        pl.col(\"close\").ewm_mean(span=89).alias(\"EMA_89\"),\n",
    "    ])\n",
    "    \n",
    "    # Step 2: Compute MACD and RSI using already-created columns\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"EMA_13\") - pl.col(\"EMA_21\")).alias(\"macd_fast\"),\n",
    "        (pl.col(\"EMA_55\") - pl.col(\"EMA_89\")).alias(\"macd_slow\"),\n",
    "    ])\n",
    "    \n",
    "    return df\n",
    "\n",
    "start_time = time.time()\n",
    "df_with_indicators = pl_resampled_df.group_by(\"symbol\", maintain_order=True).map_groups(add_indicators)\n",
    "print(f\"Indicator calculation time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\nFirst 10 rows of result:\")\n",
    "print(df_with_indicators.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "class TrendAlertProcessor:\n",
    "    \"\"\"\n",
    "    TrendAlertProcessor using Polars for efficient processing of financial time series data.\n",
    "    Incorporates advanced trend detection algorithms from the dictionary-based implementation.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pl.DataFrame, intervals: List[int]):\n",
    "        self.df = df\n",
    "        self.intervals = intervals\n",
    "        self.rolling_window = 50\n",
    "    \n",
    "    def _add_velocity_alert(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Add velocity alerts based on the relationship between price and various EMAs.\n",
    "        Similar to velocity_alert_dict in the original implementation.\n",
    "        \"\"\"\n",
    "        # Add velocity status\n",
    "        df = df.with_columns([\n",
    "            pl.when(\n",
    "                (pl.col(\"close\") > pl.col(\"open\")) & \n",
    "                (pl.col(\"close\") > pl.max_horizontal(\"EMA_8\", \"EMA_13\")) & \n",
    "                (pl.col(\"close\") > pl.max_horizontal(\"EMA_144\", \"EMA_169\")) &\n",
    "                (pl.min_horizontal(\"EMA_8\", \"EMA_13\") > pl.max_horizontal(\"EMA_144\", \"EMA_169\"))\n",
    "            ).then(pl.lit(\"velocity_maintained\"))\n",
    "            .when(\n",
    "                (pl.col(\"close\") < pl.col(\"EMA_13\")) & \n",
    "                (pl.col(\"close\") > pl.col(\"EMA_169\"))\n",
    "            ).then(pl.lit(\"velocity_weak\"))\n",
    "            .when(\n",
    "                (pl.col(\"close\") < pl.col(\"EMA_13\")) & \n",
    "                (pl.col(\"close\") < pl.col(\"EMA_169\"))\n",
    "            ).then(pl.lit(\"velocity_loss\"))\n",
    "            .otherwise(pl.lit(\"velocity_negotiating\"))\n",
    "            .alias(\"velocity_status\")\n",
    "        ])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _add_accel_decel_alert(self, df: pl.DataFrame, interval: int) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Add acceleration/deceleration alerts based on EMA relationships and velocity status history.\n",
    "        \"\"\"\n",
    "        window_dict = {\n",
    "            1: 28, 3: 20, 5: 20, 8: 14, 13: 14\n",
    "        }\n",
    "        obs_window = window_dict.get(interval, 7)\n",
    "        \n",
    "        # First get velocity status\n",
    "        df = self._add_velocity_alert(df)\n",
    "        \n",
    "        # Count velocity statuses in the observation window\n",
    "        df = df.with_columns([\n",
    "            pl.col(\"velocity_status\").map_elements(\n",
    "                lambda s: 1 if s in [\"velocity_loss\", \"velocity_weak\", \"velocity_negotiating\"] else 0,\n",
    "                return_dtype=pl.Int32\n",
    "            ).alias(\"loss_flag\"),\n",
    "            pl.col(\"velocity_status\").map_elements(\n",
    "                lambda s: 1 if s == \"velocity_maintained\" else 0,\n",
    "                return_dtype=pl.Int32\n",
    "            ).alias(\"maintain_flag\")\n",
    "        ])\n",
    "        \n",
    "        df = df.with_columns([\n",
    "            pl.col(\"loss_flag\").rolling_sum(window_size=obs_window).alias(\"count_velocity_loss\"),\n",
    "            pl.col(\"maintain_flag\").rolling_sum(window_size=obs_window).alias(\"count_velocity_maintained\")\n",
    "        ])\n",
    "        \n",
    "        # Add acceleration/deceleration signals\n",
    "        df = df.with_columns([\n",
    "            pl.when(\n",
    "                (pl.max_horizontal(\"EMA_144\", \"EMA_169\") <= pl.max_horizontal(\"EMA_8\", \"EMA_13\")) &\n",
    "                (pl.col(\"open\") < pl.col(\"close\")) &\n",
    "                (pl.col(\"count_velocity_loss\") > pl.col(\"count_velocity_maintained\"))\n",
    "            ).then(pl.lit(\"accelerated\"))\n",
    "            .when(\n",
    "                (pl.col(\"close\") < pl.min_horizontal(\"EMA_8\", \"EMA_13\")) &\n",
    "                (pl.col(\"count_velocity_maintained\") < pl.col(\"count_velocity_loss\"))\n",
    "            ).then(pl.lit(\"decelerated\"))\n",
    "            .otherwise(None).alias(\"momentum_signal\")\n",
    "        ])\n",
    "        \n",
    "        # Create alert\n",
    "        momentum_alerts = df.filter(pl.col(\"momentum_signal\").is_not_null())\n",
    "        momentum_alerts = momentum_alerts.with_columns([\n",
    "            pl.lit(\"momentum_alert\").alias(\"alert_type\"),\n",
    "            pl.col(\"momentum_signal\").alias(\"signal\"),\n",
    "            pl.lit(interval).alias(\"interval\")\n",
    "        ])\n",
    "        \n",
    "        return momentum_alerts.select(\"symbol\", \"date\", \"interval\", \"alert_type\", \"signal\")\n",
    "    \n",
    "    def _add_ema_touch_alert(self, df: pl.DataFrame, interval: int) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Add alerts for when price touches or comes close to important EMAs.\n",
    "        \"\"\"\n",
    "        tolerance_dict = {\n",
    "            1: 0.002, 3: 0.02, 5: 0.05, 8: 0.07, 13: 0.1\n",
    "        }\n",
    "        tolerance = tolerance_dict.get(interval, 0.02)\n",
    "        \n",
    "        # Calculate tolerance bands around EMAs\n",
    "        df = df.with_columns([\n",
    "            pl.min_horizontal(\n",
    "                pl.col(\"EMA_144\"), pl.col(\"EMA_169\")\n",
    "            ).fill_null(pl.col(\"EMA_13\")).alias(\"long_term_min\"),\n",
    "            \n",
    "            pl.max_horizontal(\n",
    "                pl.col(\"EMA_144\"), pl.col(\"EMA_169\")\n",
    "            ).fill_null(pl.col(\"EMA_13\")).alias(\"long_term_max\"),\n",
    "            \n",
    "            pl.min_horizontal(\n",
    "                pl.col(\"EMA_8\"), pl.col(\"EMA_13\")\n",
    "            ).alias(\"short_term_min\"),\n",
    "            \n",
    "            pl.max_horizontal(\n",
    "                pl.col(\"EMA_8\"), pl.col(\"EMA_13\")\n",
    "            ).alias(\"short_term_max\")\n",
    "        ])\n",
    "        \n",
    "        # Calculate tolerance bands\n",
    "        df = df.with_columns([\n",
    "            (pl.col(\"long_term_min\") * (1 - tolerance)).alias(\"lower_bound\"),\n",
    "            (pl.col(\"long_term_max\") * (1 + tolerance)).alias(\"upper_bound\")\n",
    "        ])\n",
    "        \n",
    "        # Detect touches\n",
    "        df = df.with_columns([\n",
    "            pl.when(\n",
    "                ((pl.col(\"low\") <= pl.col(\"upper_bound\")) & (pl.col(\"low\") >= pl.col(\"lower_bound\"))) |\n",
    "                ((pl.col(\"EMA_13\") <= pl.col(\"upper_bound\")) & (pl.col(\"EMA_13\") >= pl.col(\"lower_bound\"))) |\n",
    "                ((pl.col(\"EMA_8\") <= pl.col(\"upper_bound\")) & (pl.col(\"EMA_8\") >= pl.col(\"lower_bound\")))\n",
    "            ).then(\n",
    "                pl.when(\n",
    "                    (pl.col(\"short_term_min\") > pl.col(\"long_term_max\")) &\n",
    "                    (pl.min_horizontal(pl.col(\"close\"), pl.col(\"open\")) > pl.col(\"long_term_min\"))\n",
    "                ).then(pl.lit(\"support\"))\n",
    "                .when(\n",
    "                    (pl.col(\"short_term_max\") < pl.col(\"long_term_max\")) &\n",
    "                    (pl.col(\"close\") < pl.col(\"long_term_max\"))\n",
    "                ).then(pl.lit(\"resistance\"))\n",
    "                .otherwise(pl.lit(\"neutral\"))\n",
    "            ).otherwise(None).alias(\"ema_touch_type\")\n",
    "        ])\n",
    "        \n",
    "        # Filter for touches and create alert\n",
    "        ema_touch_alerts = df.filter(pl.col(\"ema_touch_type\").is_not_null())\n",
    "        ema_touch_alerts = ema_touch_alerts.with_columns([\n",
    "            pl.lit(\"ema_touch\").alias(\"alert_type\"),\n",
    "            pl.col(\"ema_touch_type\").alias(\"signal\"),\n",
    "            pl.lit(interval).alias(\"interval\")\n",
    "        ])\n",
    "        \n",
    "        return ema_touch_alerts.select(\"symbol\", \"date\", \"interval\", \"alert_type\", \"signal\")\n",
    "    \n",
    "    def apply(self) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Apply all alert detection algorithms and return a combined DataFrame of alerts.\n",
    "        \"\"\"\n",
    "        all_alerts = []\n",
    "        \n",
    "        for interval in self.intervals:\n",
    "            df_interval = self.df.filter(pl.col(\"interval\") == interval)\n",
    "            \n",
    "            # No empty DataFrames\n",
    "            if df_interval.height == 0:\n",
    "                continue\n",
    "                \n",
    "            # Add velocity alerts\n",
    "            velocity_df = self._add_velocity_alert(df_interval)\n",
    "            velocity_alerts = velocity_df.with_columns([\n",
    "                pl.lit(\"velocity_alert\").alias(\"alert_type\"),\n",
    "                pl.col(\"velocity_status\").alias(\"signal\"),\n",
    "                pl.lit(interval).alias(\"interval\")\n",
    "            ]).select(\"symbol\", \"date\", \"interval\", \"alert_type\", \"signal\")\n",
    "            \n",
    "            # Add momentum alerts\n",
    "            momentum_alerts = self._add_accel_decel_alert(df_interval, interval)\n",
    "            \n",
    "            # Add EMA touch alerts\n",
    "            ema_touch_alerts = self._add_ema_touch_alert(df_interval, interval)\n",
    "            \n",
    "            # Combine all alerts for this interval\n",
    "            all_alerts.extend([\n",
    "                velocity_alerts,\n",
    "                momentum_alerts,\n",
    "                ema_touch_alerts\n",
    "            ])\n",
    "        \n",
    "        # Combine all alerts into a single DataFrame\n",
    "        if all_alerts:\n",
    "            return pl.concat(all_alerts)\n",
    "        else:\n",
    "            # Return empty DataFrame with correct schema if no alerts\n",
    "            return pl.DataFrame({\n",
    "                \"symbol\": [],\n",
    "                \"date\": [],\n",
    "                \"interval\": [],\n",
    "                \"alert_type\": [],\n",
    "                \"signal\": []\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌────────┬────────────────────────────────┬──────────┬────────────────┬──────────────────────┐\n",
      "│ symbol ┆ date                           ┆ interval ┆ alert_type     ┆ signal               │\n",
      "│ ---    ┆ ---                            ┆ ---      ┆ ---            ┆ ---                  │\n",
      "│ str    ┆ datetime[μs, America/Edmonton] ┆ i32      ┆ str            ┆ str                  │\n",
      "╞════════╪════════════════════════════════╪══════════╪════════════════╪══════════════════════╡\n",
      "│ A      ┆ 1999-11-18 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_negotiating │\n",
      "│ A      ┆ 1999-11-19 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_loss        │\n",
      "│ A      ┆ 1999-11-22 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_negotiating │\n",
      "│ A      ┆ 1999-11-23 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_loss        │\n",
      "│ A      ┆ 1999-11-24 00:00:00 MST        ┆ 1        ┆ velocity_alert ┆ velocity_loss        │\n",
      "└────────┴────────────────────────────────┴──────────┴────────────────┴──────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "trend_alert = TrendAlertProcessor(df_with_indicators, intervals=[1, 3, 5, 8, 13])\n",
    "alert_df = trend_alert.apply()\n",
    "print(alert_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
