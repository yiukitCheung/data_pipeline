{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yiukitcheung/Documents/Projects/condvest/data_pipeline/jupyter_notebook\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import polars as pl\n",
    "import dotenv\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "from config import load_setting\n",
    "settings = load_setting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Gold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to connect to: process/storage/gold/gold_data.parquet\n",
      "Connection Failed No such file or directory (os error 2): process/storage/gold/gold_data.parquet\n",
      "\n",
      "This error occurred with the following context stack:\n",
      "\t[1] 'parquet scan'\n",
      "\t[2] 'sink'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test connection to Silver Data db\n",
    "try:\n",
    "    parquet_path = settings['process']['gold_data_path']\n",
    "    print(f\"Attempting to connect to: {parquet_path}\")\n",
    "    # Test Connection with a simple query\n",
    "    pl_df = pl.read_parquet(parquet_path)\n",
    "    pl_df = pl_df.sort([\"date\"], descending=True)\n",
    "    print(\"Connection Succesfful!\")\n",
    "    print(f\"Test query result: {pl_df}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Connection Failed {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold data file size: 2.90 MB\n",
      "Number of rows: 1257\n",
      "Number of columns: 5\n"
     ]
    }
   ],
   "source": [
    "# Get the size of the gold data\n",
    "# Get file size in bytes\n",
    "file_size_bytes = os.path.getsize(parquet_path)\n",
    "\n",
    "# Convert to more readable format\n",
    "def convert_size(size_bytes):\n",
    "    \"\"\"Convert bytes to human readable format\"\"\"\n",
    "    for unit in ['B', 'KB', 'MB', 'GB']:\n",
    "        if size_bytes < 1024.0:\n",
    "            return f\"{size_bytes:.2f} {unit}\"\n",
    "        size_bytes /= 1024.0\n",
    "    return f\"{size_bytes:.2f} GB\"\n",
    "\n",
    "print(f\"Gold data file size: {convert_size(file_size_bytes)}\")\n",
    "print(f\"Number of rows: {len(pl_df)}\")\n",
    "print(f\"Number of columns: {len(pl_df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set to Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BLK', 'CHT', 'VATE', 'VKTX', 'CHY', 'CI', 'CHWY', 'FMS', 'NVMI', 'ABT', 'DSGX', 'KEN', 'ZG', 'AMP', 'ALRM', 'AMD', 'META', 'VIRT', 'ZBRA', 'AAON', 'HASI', 'SCL', 'PRGO', 'DKL', 'TAL', 'SWTX', 'DQ', 'APDN', 'BILI', 'CLW', 'VEEV', 'DRS', 'MBOT', 'NVAX', 'JD', 'FITBI', 'SCPH', 'CHPT', 'ANGI', 'CLLS', 'AAPL', 'MHLD', 'HMC', 'FR', 'BL', 'VERI', 'SCNX', 'IZEA', 'JOUT', 'AMRC', 'SFIX', 'XYZ', 'POWI', 'AAMI', 'FI', 'YUMC', 'ALTS', 'APD', 'FFIV', 'DT', 'TAK', 'DGX', 'YEXT', 'SBAC', 'VHC', 'VIVK', 'BLD', 'FMC', 'AMAT', 'SCNI', 'FF', 'FOLD', 'VIR', 'BIPC', 'MDB', 'VIVS', 'MBUU', 'TEL', 'DOMO', 'AMPH', 'MGNX', 'MCRI', 'ABUS', 'PODD', 'SYRE', 'NTES', 'SCCO', 'DOCU', 'TER', 'TFX', 'FLWS', 'BMY', 'HLF', 'MCK', 'SGRY', 'BLFS', 'TEAM', 'ZWS', 'SDGR', 'PRAA', 'VRNS', 'POWW', 'AMT', 'DKNG', 'K', 'MEIP', 'AMCR', 'TBPH', 'DRD', 'AMH', 'BLDP', 'ZTO', 'PRI', 'BKYI', 'PLD', 'ZM', 'AAP', 'JNPR', 'ADBE', 'VC', 'XYLO', 'ACM', 'NTLA', 'CLWT', 'CLS', 'BMRN', 'ACN', 'JOYY', 'ANSS', 'DLHC', 'DNLI', 'VCYT', 'CLDX', 'PLXS', 'MCO', 'BILL', 'MCFT', 'AME', 'KAI', 'PMTS', 'HCI', 'MC', 'CMI', 'AMBA', 'ZYXI', 'VRT', 'ANET', 'BMI', 'PROF', 'BIO', 'NXE', 'PKG', 'HMY', 'JHX', 'SEDG', 'VRME', 'MED', 'MHO', 'BLDR', 'KALA', 'AMTX', 'HOLX', 'SYK', 'HDSN', 'TFII', 'VRTX', 'MBRX', 'ZS', 'ITRM', 'SE', 'Z', 'CHRS', 'YMAB', 'SGMO', 'SAP', 'ACHC', 'HL', 'TECX', 'NSC', 'SBSW', 'ADAP', 'MCHP', 'KBH', 'VNET', 'AMSC', 'ANY', 'DKS', 'CHI', 'DOOO', 'MESO', 'SFM', 'PRGS', 'NTCT', 'BHP', 'TEVA', 'ADSK', 'NUS', 'FLGT', 'NRG', 'ADI', 'DVAX', 'PLUG', 'FICO']\n",
      "203\n"
     ]
    }
   ],
   "source": [
    "# Get the last row of the gold data\n",
    "long_accelerating = pl_df.tail(1).select([\"long_accelerating\"]).to_dicts()[0][\"long_accelerating\"]\n",
    "print(long_accelerating)\n",
    "print(len(long_accelerating))\n",
    "\n",
    "# Cache long-accelerating to Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
