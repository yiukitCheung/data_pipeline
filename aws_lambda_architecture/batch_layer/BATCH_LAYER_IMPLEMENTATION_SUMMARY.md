# ğŸ“¦ Batch Layer Implementation Summary

## ğŸ‰ Completed Components

### âœ… 1. AWS Lambda Fetchers (Production Ready)

**Status:** âœ… **DEPLOYED AND RUNNING**

#### 1.1 Daily OHLCV Fetcher (`daily_ohlcv_fetcher.py`)
- **Function:** Fetches daily OHLCV data from Polygon API
- **Schedule:** EventBridge rule triggers after market close (4:05 PM ET)
- **Features:**
  - Async fetching (10x faster)
  - Smart backfill for missing dates
  - Timezone-aware (Eastern Time)
  - Watermark table for incremental processing
  - Dual write: S3 Bronze + RDS

**S3 Output Path:**
```
s3://dev-condvest-datalake/bronze/raw_ohlcv/
â”œâ”€â”€ symbol=AAPL/
â”‚   â”œâ”€â”€ data.parquet          â† Consolidated (fast reads)
â”‚   â”œâ”€â”€ date=2025-11-19.parquet  â† Daily incremental
â”‚   â”œâ”€â”€ date=2025-11-20.parquet
â”‚   â””â”€â”€ ...
â”œâ”€â”€ symbol=MSFT/
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

#### 1.2 Metadata Fetcher (`daily_meta_fetcher.py`)
- **Function:** Fetches stock metadata (name, industry, sector, etc.)
- **Schedule:** EventBridge rule triggers daily
- **Features:**
  - Updates symbol_metadata table in RDS
  - Handles new symbols automatically

---

### âœ… 2. AWS Batch Resampler (Production Ready)

**Status:** âœ… **DEPLOYED AND SCHEDULED**

**File:** `processing/batch_jobs/resampler.py`

**AWS Resources:**
| Resource | Name | Status |
|----------|------|--------|
| Job Definition | `dev-batch-duckdb-resampler` | âœ… Active |
| EventBridge Rule | `dev-resampler-daily-schedule` | âœ… Enabled |
| Schedule | Daily at 21:20 UTC (4:20 PM ET) | âœ… Configured |
| Docker Image | `dev-batch-processor:latest` | âœ… Built |

**Achievement:**
- Successfully processed **10,842,928 records** across all 6 Fibonacci intervals
- Execution time: ~1.9 hours for full historical data (63 years!)
- All checkpoint files created successfully

**Fibonacci Intervals:**
| Interval | Status | Description |
|----------|--------|-------------|
| 3d | âœ… Complete | 3-day resampling |
| 5d | âœ… Complete | 5-day resampling |
| 8d | âœ… Complete | 8-day resampling |
| 13d | âœ… Complete | 13-day resampling |
| 21d | âœ… Complete | 21-day resampling |
| 34d | âœ… Complete | 34-day resampling |

**S3 Silver Layer Structure:**
```
s3://dev-condvest-datalake/silver/
â”œâ”€â”€ silver_3d/
â”‚   â”œâ”€â”€ year=2020/month=01/data_3d_202001.parquet
â”‚   â””â”€â”€ ...
â”œâ”€â”€ silver_5d/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ silver_8d/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ silver_13d/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ silver_21d/
â”‚   â””â”€â”€ ...
â””â”€â”€ silver_34d/
    â””â”€â”€ ...
```

**Checkpoint System:**
```
s3://dev-condvest-datalake/processing_metadata/
â”œâ”€â”€ silver_3d_checkpoint.json   âœ…
â”œâ”€â”€ silver_5d_checkpoint.json   âœ…
â”œâ”€â”€ silver_8d_checkpoint.json   âœ…
â”œâ”€â”€ silver_13d_checkpoint.json  âœ…
â”œâ”€â”€ silver_21d_checkpoint.json  âœ…
â””â”€â”€ silver_34d_checkpoint.json  âœ…
```

**Key Features:**
- Reads from consolidated `data.parquet` files (fast!)
- Incremental processing via checkpoint system
- DuckDB for high-performance SQL analytics
- 5-year data filter for accurate Fibonacci resampling

---

### âœ… 3. Bronze Layer Consolidation Job (DEPLOYED!)

**Status:** âœ… **DEPLOYED TO AWS BATCH + EVENTBRIDGE SCHEDULED**

**File:** `processing/batch_jobs/consolidator.py`

**AWS Resources:**
| Resource | Name | Status |
|----------|------|--------|
| Job Definition | `dev-batch-bronze-consolidator` | âœ… Active |
| EventBridge Rule | `dev-consolidator-daily-schedule` | âœ… Enabled |
| Schedule | Daily at 21:10 UTC (4:10 PM ET) | âœ… Configured |
| Docker Image | `dev-batch-processor:latest` | âœ… Built |

**Purpose:** Merges daily `date=*.parquet` files into single `data.parquet` per symbol for fast reading.

**Architecture:**
```
Lambda Fetcher writes:  symbol=AAPL/date=2025-11-19.parquet (daily)
                        symbol=AAPL/date=2025-11-20.parquet (daily)
                        
Consolidation Job:      symbol=AAPL/data.parquet (merged, incremental)

Resampler reads:        symbol=*/data.parquet (fast!)
```

**Key Features:**
- **Parallel Processing:** 10 workers (5-8x faster than sequential)
- **Incremental Processing:** Only consolidates symbols with new data
- **Metadata-Driven:** Uses RDS watermark table + consolidation manifest
- **Industry Standard:** Similar to Delta Lake, Iceberg, Hudi compaction
- **Integrated Cleanup:** Removes old date files after consolidation

**Performance (Local Test - 5,419 Symbols):**
| Metric | Value |
|--------|-------|
| Total Time | 8.5 minutes |
| Throughput | 10.6 symbols/sec |
| Symbols Consolidated | 5,345 |
| Files Cleaned | 1,210 |
| Space Freed | 2.73 MB |
| Errors | 0 |

**Consolidation Manifest:**
```
s3://dev-condvest-datalake/processing_metadata/consolidation_manifest.parquet
```
| symbol | last_consolidated_date | row_count | last_updated |
|--------|------------------------|-----------|--------------|
| AAPL   | 2025-12-06            | 11,315    | 2025-12-06   |
| MSFT   | 2025-12-06            | 11,501    | 2025-12-06   |

**Manual Trigger:**
```bash
aws batch submit-job \
  --job-name manual-consolidator-$(date +%Y%m%d%H%M%S) \
  --job-queue dev-batch-duckdb-resampler \
  --job-definition dev-batch-bronze-consolidator \
  --region ca-west-1
```

---

### âœ… 4. Bronze Layer Vacuum/Cleanup Script (Local)

**Status:** âœ… **IMPLEMENTED (Local Script)**

**File:** `processing/batch_jobs/vaccume.py`

**Purpose:** Removes old `date=*.parquet` files after consolidation to reduce S3 storage and improve read performance.

**Note:** This script runs locally, not deployed to AWS. The consolidator job has integrated cleanup, so vacuum is only needed for manual maintenance.

**Logic:**
| Scenario | Action |
|----------|--------|
| Symbol WITH `data.parquet` | Delete `date=*.parquet` older than 30 days |
| Symbol WITHOUT `data.parquet` | Don't touch (preserve all files) |
| Recent files (< 30 days) | Keep as safety buffer |

**Key Features:**
- **Parallel Processing:** 10 workers for fast cleanup
- **Dry Run Mode:** Preview what would be deleted
- **Cleanup Manifest:** Tracks cleanup operations

**Usage:**
```bash
# Dry run (see what would be deleted)
python vaccume.py --dry-run

# Run cleanup on specific symbols
python vaccume.py --symbols AAPL,MSFT,GOOGL

# Run full cleanup with parallel processing
python vaccume.py --max-workers 10

# Custom retention period
python vaccume.py --retention-days 60
```

---

### âœ… 5. AWS Step Functions Pipeline Orchestration (DEPLOYED!)

**Status:** âœ… **DEPLOYED AND SCHEDULED**

**File:** `infrastructure/orchestration/state_machine_definition.json`

**AWS Resources:**
| Resource | Name | Status |
|----------|------|--------|
| State Machine | `condvest-daily-ohlcv-pipeline` | âœ… Active |
| IAM Role | `condvest-pipeline-step-functions-role` | âœ… Created |
| EventBridge Rule | `condvest-daily-pipeline-trigger` | âœ… Enabled |
| Schedule | Daily at 21:05 UTC (4:05 PM ET) | âœ… Configured |
| SNS Topic | `condvest-pipeline-alerts` | âœ… Created |

**Pipeline Architecture:**
```
                     Step Functions: condvest-daily-ohlcv-pipeline
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚              STAGE 1: PARALLEL FETCHERS                          â”‚    â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚    â”‚
â”‚   â”‚  â”‚   Lambda: OHLCV Fetcher â”‚   â”‚  Lambda: Meta Fetcher   â”‚      â”‚    â”‚
â”‚   â”‚  â”‚   (2 retries)           â”‚   â”‚  (2 retries)            â”‚      â”‚    â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚    â”‚
â”‚   â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                â–¼                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚              STAGE 2: CONSOLIDATOR (Sequential)                   â”‚    â”‚
â”‚   â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚    â”‚
â”‚   â”‚              â”‚  AWS Batch: Consolidator    â”‚                      â”‚    â”‚
â”‚   â”‚              â”‚  (1 retry, 60s interval)    â”‚                      â”‚    â”‚
â”‚   â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                â–¼                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚              STAGE 3: PARALLEL RESAMPLERS (6x)                    â”‚    â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”       â”‚    â”‚
â”‚   â”‚   â”‚ 3d  â”‚  â”‚ 5d  â”‚  â”‚ 8d  â”‚  â”‚ 13d  â”‚  â”‚ 21d  â”‚  â”‚ 34d  â”‚       â”‚    â”‚
â”‚   â”‚   â””â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”˜       â”‚    â”‚
â”‚   â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                    â–¼                                       â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                          â”‚  âœ… Pipeline Complete â”‚                          â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                                            â”‚
â”‚   ON FAILURE â†’ SNS: condvest-pipeline-alerts â†’ Email Notification         â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Benefits:**
- **âš¡ Parallel Execution:** Fetchers run in parallel, all 6 resamplers run in parallel
- **ğŸ”„ Automatic Retries:** Lambda (2 retries), Batch (1 retry)
- **ğŸ”— Sequential Dependencies:** Consolidator waits for fetchers, resamplers wait for consolidator
- **ğŸ“§ Failure Alerts:** SNS notification on any stage failure
- **ğŸ“Š Visual Monitoring:** AWS Console shows real-time execution graph
- **â±ï¸ ~3x Faster:** Parallel resamplers vs sequential (all 6 intervals at once!)

**Manual Trigger:**
```bash
aws stepfunctions start-execution \
  --state-machine-arn "arn:aws:states:ca-west-1:471112909340:stateMachine:condvest-daily-ohlcv-pipeline" \
  --name "manual-$(date +%Y%m%d%H%M%S)" \
  --region ca-west-1
```

---

## ğŸ“Š Complete Data Pipeline Flow

### Daily Schedule (Orchestrated by Step Functions)

| Stage | Components | Execution | Duration |
|-------|------------|-----------|----------|
| **1. Fetchers** | OHLCV + Meta | **Parallel** | ~5 min |
| **2. Consolidator** | Bronze layer merge | **Sequential** | ~8 min |
| **3. Resamplers** | 3d, 5d, 8d, 13d, 21d, 34d | **Parallel (6x)** | ~5 min |

**Total Pipeline Time:** ~18 minutes (optimized from ~30+ minutes sequential)

**EventBridge Trigger:** Daily at **21:05 UTC** (4:05 PM ET)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BATCH LAYER DATA FLOW (STEP FUNCTIONS)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚   Market Close: 4:00 PM ET (21:00 UTC)                                     â”‚
â”‚          â”‚                                                                 â”‚
â”‚          â–¼ 21:05 UTC                                                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  EventBridge â†’ Step Functions: condvest-daily-ohlcv-pipeline        â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                  â–¼                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  STAGE 1: Parallel Fetchers                                          â”‚  â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚  â”‚
â”‚   â”‚   â”‚  Lambda: OHLCV        â”‚   â”‚  Lambda: Metadata     â”‚             â”‚  â”‚
â”‚   â”‚   â”‚  â†’ S3 Bronze          â”‚   â”‚  â†’ RDS symbol_metadataâ”‚             â”‚  â”‚
â”‚   â”‚   â”‚  â†’ RDS raw_ohlcv      â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚  â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜  â”‚
â”‚                                                                       â”‚    â”‚
â”‚                                  â–¼                                    â”‚    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  STAGE 2: Consolidator (Sequential)                                  â”‚  â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚   â”‚   â”‚  AWS Batch: dev-batch-bronze-consolidator                     â”‚ â”‚  â”‚
â”‚   â”‚   â”‚  â†’ Merges date=*.parquet â†’ data.parquet (per symbol)          â”‚ â”‚  â”‚
â”‚   â”‚   â”‚  â†’ Cleans up old date files (>30 days)                        â”‚ â”‚  â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜  â”‚
â”‚                                                                       â”‚    â”‚
â”‚                                  â–¼                                    â”‚    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  STAGE 3: Parallel Resamplers (6 intervals simultaneously)           â”‚  â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”           â”‚  â”‚
â”‚   â”‚   â”‚  3d  â”‚ â”‚  5d  â”‚ â”‚  8d  â”‚ â”‚ 13d  â”‚ â”‚ 21d  â”‚ â”‚ 34d  â”‚           â”‚  â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜           â”‚  â”‚
â”‚   â”‚   â†’ Read from data.parquet â†’ Write to S3 Silver layer              â”‚  â”‚
â”‚   â”‚   â†’ Last 5 years data only (RESAMPLING_RETENTION_YEARS=5)          â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜  â”‚
â”‚                                                                       â”‚    â”‚
â”‚                                  â–¼                                    â”‚    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  âœ… PIPELINE COMPLETE                                                â”‚  â”‚
â”‚   â”‚    â†’ Fresh data available for analytics/backtesting                 â”‚  â”‚
â”‚   â”‚    â†’ Duration: ~18 minutes                                          â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                            â”‚
â”‚   ON FAILURE AT ANY STAGE:                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  ğŸš¨ SNS: condvest-pipeline-alerts                                    â”‚  â”‚
â”‚   â”‚    â†’ Email notification with error details                          â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Jobs Summary

| Job | Type | File | Triggered By | Purpose |
|-----|------|------|--------------|---------|
| **OHLCV Fetcher** | Lambda | `daily_ohlcv_fetcher.py` | Step Functions | Fetch daily OHLCV data |
| **Meta Fetcher** | Lambda | `daily_meta_fetcher.py` | Step Functions | Fetch symbol metadata |
| **Consolidator** | AWS Batch | `consolidator.py` | Step Functions | Merge date files + cleanup |
| **Resampler (6x)** | AWS Batch | `resampler.py` | Step Functions (parallel) | Fibonacci resampling |
| **Vacuum** | Local Script | `vaccume.py` | Manual | Deep clean old date files |

### Orchestration
| Resource | Name | Schedule |
|----------|------|----------|
| **Step Functions** | `condvest-daily-ohlcv-pipeline` | 21:05 UTC daily |
| **EventBridge Rule** | `condvest-daily-pipeline-trigger` | Triggers Step Functions |
| **SNS Alerts** | `condvest-pipeline-alerts` | On failure notification |

---

## ğŸš€ Daily Execution Order (Step Functions Orchestrated)

**Single EventBridge Rule triggers the entire pipeline automatically via Step Functions:**

```
Market Close (4:00 PM ET / 21:00 UTC)
         â”‚
         â–¼ 21:05 UTC
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ EventBridge â†’ Step Functions                            â”‚
   â”‚   condvest-daily-ohlcv-pipeline                         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ STAGE 1 (PARALLEL)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ OHLCV Fetcher       â”‚  Metadata Fetcher                 â”‚
   â”‚ (Lambda)            â”‚  (Lambda)                         â”‚
   â”‚ â†’ S3 Bronze + RDS   â”‚  â†’ RDS symbol_metadata            â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ STAGE 2 (SEQUENTIAL - waits for Stage 1)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Consolidator (AWS Batch)                                â”‚
   â”‚ â†’ Merges date=*.parquet â†’ data.parquet                  â”‚
   â”‚ â†’ Cleans up old date files (>30 days)                   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ STAGE 3 (PARALLEL - 6 jobs simultaneously)
   â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
   â”‚  3d â”‚  5d â”‚  8d â”‚ 13d  â”‚ 21d  â”‚ 34d  â”‚  â† 6x Resamplers (AWS Batch)
   â”‚     â”‚     â”‚     â”‚      â”‚      â”‚      â”‚    Running in parallel!
   â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ ~21:23 UTC
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ âœ… Pipeline Complete                                     â”‚
   â”‚    â†’ Fresh data available for analytics/backtesting     â”‚
   â”‚    â†’ ~18 minutes total (optimized from 30+ min)         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   ON FAILURE (any stage):
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ ğŸš¨ SNS Notification â†’ Email alert with error details    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Monthly Maintenance (Manual)
```
1. Vacuum Script (local) â†’ Deep cleanup of old date files if needed
2. RDS Retention Job â†’ Archive old RDS data
```

---

## ğŸ“Š Performance Metrics

### Lambda Fetcher
- **Symbols:** 5,350+
- **Daily Runtime:** ~5-10 minutes (async)
- **Records Per Day:** ~5,350
- **Cost:** ~$0.01/day

### Consolidation Job (AWS Batch)
- **Throughput:** 10.6 symbols/sec (parallel)
- **Full Run:** ~8-10 minutes (5,400+ symbols)
- **Incremental:** ~1-2 minutes (only new symbols)
- **Cost:** ~$0.05/run

### Resampler (AWS Batch)
- **Records:** 10,842,928
- **Runtime:** ~1.9 hours (full), ~5 min (incremental)
- **Cost:** ~$0.50/run

---

## ğŸ”§ AWS Batch Job Definitions

### Consolidator Job Definition
```json
{
  "jobDefinitionName": "dev-batch-bronze-consolidator",
  "type": "container",
  "containerProperties": {
    "image": "471112909340.dkr.ecr.ca-west-1.amazonaws.com/dev-batch-processor:latest",
    "command": ["python", "consolidator.py"],
    "resourceRequirements": [
      {"type": "VCPU", "value": "2"},
      {"type": "MEMORY", "value": "4096"}
    ],
    "environment": [
      {"name": "S3_BUCKET", "value": "dev-condvest-datalake"},
      {"name": "S3_PREFIX", "value": "bronze/raw_ohlcv"},
      {"name": "MODE", "value": "incremental"},
      {"name": "MAX_WORKERS", "value": "10"},
      {"name": "RETENTION_DAYS", "value": "30"}
    ]
  }
}
```

### Resampler Job Definition
```json
{
  "jobDefinitionName": "dev-batch-duckdb-resampler",
  "type": "container",
  "containerProperties": {
    "image": "471112909340.dkr.ecr.ca-west-1.amazonaws.com/dev-batch-processor:latest",
    "command": ["python", "resampler.py"],
    "resourceRequirements": [
      {"type": "VCPU", "value": "2"},
      {"type": "MEMORY", "value": "4096"}
    ],
    "environment": [
      {"name": "S3_BUCKET_NAME", "value": "dev-condvest-datalake"},
      {"name": "RESAMPLING_INTERVALS", "value": "3,5,8,13,21,34"}
    ]
  }
}
```

---

## ğŸ”§ Environment Variables

### Lambda Fetcher
```bash
POLYGON_API_KEY_SECRET_ARN=arn:aws:secretsmanager:ca-west-1:xxx
RDS_SECRET_ARN=arn:aws:secretsmanager:ca-west-1:xxx
S3_DATALAKE_BUCKET=dev-condvest-datalake
```

### Batch Jobs (Consolidator, Resampler)
```bash
S3_BUCKET=dev-condvest-datalake
S3_PREFIX=bronze/raw_ohlcv
AWS_REGION=ca-west-1
MODE=incremental
MAX_WORKERS=10
RETENTION_DAYS=30
```

---

## âœ… Implementation Checklist

### Phase 1: Data Ingestion âœ…
- [x] Lambda OHLCV Fetcher deployed
- [x] Lambda Metadata Fetcher deployed
- [x] EventBridge schedules configured
- [x] Watermark table working
- [x] S3 Bronze structure established

### Phase 2: Data Optimization âœ…
- [x] Consolidation job implemented (parallel processing)
- [x] Vacuum/cleanup script implemented
- [x] Metadata-driven incremental processing
- [x] Explicit paths for fast S3 access

### Phase 3: Data Processing âœ…
- [x] Resampler reading from data.parquet
- [x] Checkpoint system working
- [x] Silver layer validated
- [x] All 6 Fibonacci intervals processed

### Phase 4: Production âœ…
- [x] Consolidation job deployed to AWS Batch
- [x] EventBridge schedule for consolidator (daily 6 AM UTC)
- [x] Docker container with both resampler and consolidator
- [x] CloudWatch logs configured

### Phase 5: Monitoring âœ…
- [x] Step Functions visual execution monitoring
- [x] SNS notifications on pipeline failures (`condvest-pipeline-alerts`)
- [x] Automatic retry logic for Lambda (2x) and Batch (1x)
- [ ] CloudWatch alarms for custom metrics (optional)
- [ ] Dashboard for pipeline health (optional)

---

## ğŸ“‚ File Structure

```
aws_lambda_architecture/batch_layer/
â”œâ”€â”€ fetching/
â”‚   â”œâ”€â”€ lambda_functions/
â”‚   â”‚   â”œâ”€â”€ daily_ohlcv_fetcher.py  â† Lambda: fetch OHLCV
â”‚   â”‚   â””â”€â”€ daily_meta_fetcher.py   â† Lambda: fetch metadata
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ processing/
â”‚   â””â”€â”€ batch_jobs/
â”‚       â”œâ”€â”€ consolidator.py         â† Batch: consolidate bronze layer
â”‚       â”œâ”€â”€ resampler.py            â† Batch: Fibonacci resampling
â”‚       â”œâ”€â”€ vaccume.py              â† Local: cleanup old files
â”‚       â”œâ”€â”€ recover_gap_data.py     â† Utility: recover missing data from RDS
â”‚       â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ fetching/
â”‚   â”‚   â””â”€â”€ deployment_packages/
â”‚   â”‚       â””â”€â”€ deploy_lambda.sh    â† Lambda deployment script
â”‚   â”œâ”€â”€ processing/
â”‚   â”‚   â”œâ”€â”€ Dockerfile              â† Supports both jobs
â”‚   â”‚   â”œâ”€â”€ build_batch_container.sh â† Build & push container to ECR
â”‚   â”‚   â””â”€â”€ deploy_batch_jobs.sh    â† Deploy job definitions & schedules
â”‚   â”œâ”€â”€ orchestration/
â”‚   â”‚   â”œâ”€â”€ state_machine_definition.json  â† Step Functions definition
â”‚   â”‚   â”œâ”€â”€ deploy_step_functions.sh       â† Deploy pipeline
â”‚   â”‚   â””â”€â”€ README.md                      â† Orchestration documentation
â”‚   â””â”€â”€ modules/processing/
â”‚       â””â”€â”€ main.tf                 â† Terraform: job definitions
â”‚
â””â”€â”€ BATCH_LAYER_IMPLEMENTATION_SUMMARY.md
```

---

**Last Updated:** December 10, 2025  
**Status:** âœ… Batch Layer 100% Complete - All jobs deployed and orchestrated via Step Functions

**Daily Pipeline (Automated via Step Functions):**
- **21:05 UTC** - EventBridge triggers `condvest-daily-ohlcv-pipeline`
- **Stage 1** - OHLCV + Metadata Fetchers (parallel)
- **Stage 2** - Consolidator (sequential, waits for Stage 1)
- **Stage 3** - 6x Resamplers (parallel: 3d, 5d, 8d, 13d, 21d, 34d)
- **~21:23 UTC** - Pipeline complete (~18 minutes total)
- **On Failure** - SNS notification to `condvest-pipeline-alerts`
