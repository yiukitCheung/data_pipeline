# Welcome to your prefect.yaml file! You can use this file for storing and managing
# configuration for deploying your flows. We recommend committing this file to source
# control along with your flow code.

# Generic metadata about this project
name: data_pipeline
prefect-version: 3.4.1

# build section allows you to manage and build docker images
build:

# push section allows you to manage if and how this project is uploaded to remote locations
push:

# pull section allows you to provide instructions for cloning this project in remote locations
pull:

# the deployments section allows you to provide configuration for deploying flows
deployments:
- name: silver-pipeline-deployment
  version:
  tags: []
  concurrency_limit:
  description: Silver pipeline for data processing
  entrypoint: flows/make_silver_pipeline.py:silver_pipeline
  parameters: {}
  work_pool:
    name: silver-pipeline
    work_queue_name: silver-pipeline
    job_variables: {}
  schedules:
  - cron: 05 16 * * 1-5
    timezone: America/New_York
    day_or: true
    active: true
  pull:
  - prefect.deployments.steps.set_working_directory:
      directory: /Users/yiukitcheung/Desktop/data_pipeline
- name: bronze-pipeline-deployment
  version:
  tags: []
  concurrency_limit:
  description: Main pipeline flow â€” runs after market close if today is a trading
    day
  entrypoint: flows/daily_pipeline.py:bronze_pipeline
  parameters:
    settings:
      data_extract:
        meta:
          topic_names: meta
          table_name: symbol_metadata
          chunk_size: 5000
          batch_size: 5000
        raw:
          rate_limit: 10
          chunk_delay: 10
          max_workers: 10
          batch_size: 1000
          max_batch_time: 120
        datastream:
          batch:
            support_resistance: support_resistance_alert
            volume_spike: volume_spike_alert
          base_interval: 1m
          expireAfterSeconds: 6048000
          window_size: 5
        databatch:
          table_name: raw
          base_interval: 1d
      process:
        datastream:
          required_intervals:
          - 5m
          - 30m
          - 60m
          expireAfterSeconds: 6048000
          window_size:
            support_resistance: 5
            volume_spike: 10
        databatch:
          processed_db_name: processed_market_data
          train_data_repository_collection_name: trainable_data_repository
          new_intervals:
          - 1
          - 3
          - 5
          - 8
          - 13
      analytics:
        alert:
          long_term: long_term_alert
          live: live_streaming_alerts
        sandbox_results:
          long_term: sandbox_data
          short_term: sandbox_data
        candidates:
          long_term: long_term_candidates
          short_term: short_term_candidates
        trades:
          long_term: long_term_sandbox_results
          short_term: short_term_sandbox_results
      mode: production
  work_pool:
    name: bronze-pipeline
    work_queue_name:
    job_variables: {}
  schedules:
  - cron: 00 16 * * 1-5
    timezone: America/New_York
    day_or: true
    active: true
  - cron: 00 16 * * 1-5
    timezone: America/New_York
    day_or: true
    active: true
  pull:
  - prefect.deployments.steps.set_working_directory:
      directory: /Users/yiukitcheung/Desktop/data_pipeline
