# Welcome to your prefect.yaml file! You can use this file for storing and managing
# configuration for deploying your flows. We recommend committing this file to source
# control along with your flow code.

# Generic metadata about this project
name: data_pipeline
prefect-version: 3.4.1

# Common configurations
common_working_directory: /Users/yiukitcheung/Desktop/data_pipeline

# build section allows you to manage and build docker images
build:

# push section allows you to manage if and how this project is uploaded to remote locations
push:

# pull section allows you to provide instructions for cloning this project in remote locations
pull:

# the deployments section allows you to provide configuration for deploying flows
deployments:
- name: silver-pipeline
  version: '1'
  tags: []
  description: Silver pipeline for data processing
  entrypoint: flows/make_silver_pipeline.py:silver_pipeline
  parameters: {}
  work_pool:
    name: data-pipeline
    work_queue_name: silver
    job_variables: {}
  schedules:
  - cron: 05 16 * * 1-5
    timezone: America/New_York
    day_or: true
    active: true
  pull:
  - prefect.deployments.steps.set_working_directory:
      directory: /Users/yiukitcheung/Desktop/data_pipeline
  concurrency_limit:
- name: bronze-pipeline
  version: '1'
  tags: []
  description: Main pipeline flow â€” runs after market close if today is a trading
    day
  entrypoint: flows/make_bronze_pipeline.py:bronze_pipeline
  parameters:
    settings:
      data_extract:
        meta:
          topic_names: meta
          table_name: symbol_metadata
          chunk_size: 5000
          batch_size: 5000
        raw:
          rate_limit: 10
          chunk_delay: 10
          max_workers: 10
          batch_size: 1000
          max_batch_time: 120
      process:
        silver_db_path: process/storage/silver/resampled.duckdb
        gold_save_path: process/storage/gold
        sql_path: process/sql/resample_view.sql
        new_intervals:
        - 1
        - 3
        - 5
        - 8
        - 13
        - 21
        - 34
        - 55
        strategies:
          vegas_channel:
            intervals:
            - 1
            - 3
            - 5
            - 8
            - 13
      mode: production
  work_pool:
    name: data-pipeline
    work_queue_name: bronze
    job_variables: {}
  schedules:
  - cron: 00 16 * * 1-5
    timezone: America/New_York
    day_or: true
    active: true
  pull:
  - prefect.deployments.steps.set_working_directory:
      directory: /Users/yiukitcheung/Desktop/data_pipeline
  concurrency_limit:
- name: gold-pipeline
  version: '1'
  tags: []
  description: Make gold data from silver data
  entrypoint: flows/make_gold_pipeline.py:gold_pipeline
  parameters:
    settings:
      data_extract:
        meta:
          topic_names: meta
          table_name: symbol_metadata
          chunk_size: 5000
          batch_size: 5000
        raw:
          rate_limit: 10
          chunk_delay: 10
          max_workers: 10
          batch_size: 1000
          max_batch_time: 120
      process:
        silver_db_path: process/storage/silver/resampled.duckdb
        gold_save_path: process/storage/gold/gold_data.parquet
        sql_path: process/sql/resample_view.sql
        new_intervals:
        - 1
        - 3
        - 5
        - 8
        - 13
        - 21
        - 34
        - 55
        strategies:
          vegas_channel:
            intervals:
            - 1
            - 3
            - 5
            - 8
            - 13
      mode: production
  work_pool:
    name: data-pipeline
    work_queue_name: gold
    job_variables: {}
  schedules:
  - cron: 10 16 * * 1-5
    timezone: America/New_York
    day_or: true
    active: true
  pull:
  - prefect.deployments.steps.set_working_directory:
      directory: /Users/yiukitcheung/Desktop/data_pipeline
  concurrency_limit:
