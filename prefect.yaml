# Welcome to your prefect.yaml file! You can use this file for storing and managing
# configuration for deploying your flows. We recommend committing this file to source
# control along with your flow code.

# Generic metadata about this project
name: data_pipeline
prefect-version: 3.4.1

# Common configurations
common_working_directory: /Users/yiukitcheung/Desktop/data_pipeline

# build section allows you to manage and build docker images
build:

# push section allows you to manage if and how this project is uploaded to remote locations
push:

# pull section allows you to provide instructions for cloning this project in remote locations
pull:

# the deployments section allows you to provide configuration for deploying flows
deployments:
- name: silver-pipeline-deployment
  version:
  tags: []
  concurrency_limit:
  description: Silver pipeline for data processing
  entrypoint: flows/make_silver_pipeline.py:silver_pipeline
  parameters: {}
  work_pool:
    name: silver-pipeline
    work_queue_name: silver-pipeline
    job_variables: {}
  schedules:
  - cron: 05 16 * * 1-5
    timezone: America/New_York
    day_or: true
    active: true
  pull:
  - prefect.deployments.steps.set_working_directory:
      directory: /Users/yiukitcheung/Desktop/data_pipeline
- name: bronze-pipeline-deployment
  version:
  tags: []
  concurrency_limit:
  description: Main pipeline flow â€” runs after market close if today is a trading
    day
  entrypoint: flows/make_bronze_pipeline.py:bronze_pipeline
  parameters:
    settings:
      data_extract:    
        meta:
          topic_names: "meta"
          table_name: "symbol_metadata"
          chunk_size: 5000
          batch_size: 5000
        raw:
          rate_limit: 10
          chunk_delay: 10
          max_workers: 10
          batch_size: 1000
          max_batch_time: 120
      process:
        silver_db_path: process/storage/silver/resampled.duckdb
        gold_save_path: process/storage/gold
        sql_path: process/sql/resample_view.sql
        new_intervals:
          - 1
          - 3
          - 5
          - 8
          - 13
          - 21
          - 34
          - 55
        strategies:
          vegas_channel:
            intervals:
              - 1
              - 3
              - 5
              - 8
              - 13 
      mode: "production"

  work_pool:
    name: bronze-pipeline
    work_queue_name:
    job_variables: {}
  schedules:
  - cron: 00 16 * * 1-5
    timezone: America/New_York
    day_or: true
    active: true
  pull:
  - prefect.deployments.steps.set_working_directory:
      directory: /Users/yiukitcheung/Desktop/data_pipeline

- name: gold-pipeline-deployment
  version:
  tags: []
  concurrency_limit:
  description: Make gold data from silver data
  entrypoint: flows/make_gold_pipeline.py:gold_pipeline
  parameters:
    settings:
      data_extract:    
        meta:
          topic_names: "meta"
          table_name: "symbol_metadata"
          chunk_size: 5000
          batch_size: 5000
        raw:
          rate_limit: 10
          chunk_delay: 10
          max_workers: 10
          batch_size: 1000
          max_batch_time: 120
      process:
        silver_db_path: process/storage/silver/resampled.duckdb
        gold_save_path: process/storage/gold
        sql_path: process/sql/resample_view.sql
        new_intervals:
          - 1
          - 3
          - 5
          - 8
          - 13
          - 21
          - 34
          - 55
        strategies:
          vegas_channel:
            intervals:
              - 1
              - 3
              - 5
              - 8
              - 13 
      mode: "production"

  work_pool:
    name: gold-pipeline
    work_queue_name:
    job_variables: {}
  schedules:
  - cron: 10 16 * * 1-5
    timezone: America/New_York
    day_or: true
    active: true
  pull:
  - prefect.deployments.steps.set_working_directory:
      directory: /Users/yiukitcheung/Desktop/data_pipeline
